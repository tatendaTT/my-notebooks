{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "429112fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_colored_graph(num_nodes, colors, edge_probability, node_color_seed, edge_seed):\n",
    "    G = nx.Graph()\n",
    "    random.seed(node_color_seed)\n",
    "    edge_random = random.Random(edge_seed)\n",
    "    color_weights = {color: edge_random.uniform(0.5, 1.5) for color in colors}\n",
    "    shapes = ['circle', 'square', 'triangle']\n",
    "    shininess = ['shiny', 'not_shiny']\n",
    "\n",
    "    for i in range(1, num_nodes):\n",
    "        weight = color_weights[colors[i % len(colors)]]\n",
    "        color = colors[i % len(colors)]\n",
    "        shape = random.choice(shapes)\n",
    "        shiny = random.choice(shininess)\n",
    "        G.add_node(i, weight=weight, color=color, shape=shape, shiny=shiny)\n",
    "\n",
    "    for i in range(1, num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            if edge_random.random() < edge_probability:\n",
    "                if G.nodes[i]['color'] == G.nodes[j]['color']:\n",
    "                    G.add_edge(i, j, weight=edge_random.uniform(0.5, 1.5))\n",
    "                else:\n",
    "                    G.add_edge(i, j, weight=edge_random.uniform(0.1, 0.5))\n",
    "\n",
    "    return G\n",
    "\n",
    "def plot_colored_graph(G):\n",
    "    shape_to_marker = {'circle': 'o', 'square': 's', 'triangle': '^'}\n",
    "    node_shapes = {'circle': 'o', 'square': 's', 'triangle': '^'}\n",
    "    node_colors = [G.nodes[i]['color'] for i in G.nodes()]\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    node_markers = [node_shapes.get(G.nodes[i]['shape'], 'o') for i in G.nodes()]\n",
    "\n",
    "    for node, shape, color in zip(G.nodes, node_markers, node_colors):\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=[node], node_size=300, node_shape=shape, node_color=color)\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos)\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, start_node, end_node, color_preference):\n",
    "        self.current_node = start_node\n",
    "        self.color_preference = color_preference\n",
    "        self.visited_nodes = set()\n",
    "        self.visited_shapes = []\n",
    "        self.visited_shininess = []\n",
    "        self.start_node = start_node\n",
    "        self.end_node = end_node\n",
    "\n",
    "    def find_next_node(self, graph):\n",
    "        neighboring_nodes = list(graph.neighbors(self.current_node))\n",
    "        unvisited_neighbors = [node for node in neighboring_nodes if node not in self.visited_nodes]\n",
    "        neighbors_with_preference = [node for node in unvisited_neighbors if graph.nodes[node]['color'] == self.color_preference]\n",
    "\n",
    "        if neighbors_with_preference:\n",
    "            next_node = random.choice(neighbors_with_preference)\n",
    "        else:\n",
    "            next_node = None\n",
    "\n",
    "        return next_node\n",
    "\n",
    "    def traverse_graph(self, graph):\n",
    "        path = [self.current_node]\n",
    "\n",
    "        while self.current_node != self.end_node:\n",
    "            next_node = self.find_next_node(graph)\n",
    "            if next_node is None:\n",
    "                break\n",
    "\n",
    "            self.visited_nodes.add(next_node)\n",
    "            path.append(next_node)\n",
    "            self.visited_shapes.append(graph.nodes[next_node]['shape'])\n",
    "            self.visited_shininess.append(graph.nodes[next_node]['shiny'])\n",
    "            self.current_node = next_node\n",
    "\n",
    "        return path\n",
    "\n",
    "def simulate_agents(graph, num_agents, num_traversals):\n",
    "    agent_data = []\n",
    "\n",
    "    for traversal in range(num_traversals):\n",
    "        success_count = [0] * num_agents\n",
    "\n",
    "        for agent_id in range(num_agents):\n",
    "            start_node = random.choice(list(graph.nodes()))\n",
    "            end_node = random.choice(list(graph.nodes()))\n",
    "            color_preference = random.choice(colors)\n",
    "            agent = Agent(start_node, end_node, color_preference)\n",
    "            start_time = time.time()\n",
    "            path = agent.traverse_graph(graph)\n",
    "            end_time = time.time()\n",
    "            time_taken = end_time - start_time\n",
    "            reached_destination = agent.current_node == agent.end_node\n",
    "            if reached_destination:\n",
    "                success_count[agent_id] += 1\n",
    "\n",
    "            average_speed = len(path) / time_taken if time_taken > 0 else None\n",
    "            preferred_color_count = sum(1 for node in path if graph.nodes[node]['color'] == color_preference)\n",
    "            distinct_nodes_visited = len(set(path))\n",
    "            path_complexity = sum(1 for i in range(1, len(path)) if path[i] != path[i - 1])\n",
    "            visited_shapes = agent.visited_shapes\n",
    "            visited_shininess = agent.visited_shininess\n",
    "\n",
    "            agent_trajectory = {\n",
    "                'Agent': agent_id,\n",
    "                'Start Node': start_node,\n",
    "                'End Node': end_node,\n",
    "                'Color Preference': color_preference,\n",
    "                'Path': path,\n",
    "                'Length': len(path),\n",
    "                'Time Taken': time_taken,\n",
    "                'reached_destination': reached_destination,\n",
    "                'Preferred_Color_Count': preferred_color_count,\n",
    "                'Distinct_Nodes_Visited': distinct_nodes_visited,\n",
    "                'Path_Complexity': path_complexity,\n",
    "                'Visited_Shapes': visited_shapes,\n",
    "                'Visited_Shininess': visited_shininess\n",
    "            }\n",
    "\n",
    "            agent_data.append(agent_trajectory)\n",
    "\n",
    "    df = pd.DataFrame(agent_data)\n",
    "    return df\n",
    "\n",
    "def hierarchical_clustering(distance_matrix, linkage_method='complete', n_clusters=3):\n",
    "    Z = linkage(distance_matrix, method=linkage_method)\n",
    "    clusters = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "    return Z, clusters\n",
    "\n",
    "def jaccard_distance(set1, set2):\n",
    "    if len(set1.union(set2)) == 0:\n",
    "        return 0\n",
    "    return 1 - len(set1.intersection(set2)) / len(set1.union(set2))\n",
    "\n",
    "def evaluate_clustering_methods(num_seeds, graph_params, simulation_params):\n",
    "    results = []\n",
    "\n",
    "    for seed in range(num_seeds):\n",
    "        G = generate_colored_graph(*graph_params, node_color_seed=seed, edge_seed=seed)\n",
    "        df = simulate_agents(G, *simulation_params)\n",
    "        filtered_df = df[df['reached_destination'] == True]\n",
    "        filtered_df = filtered_df[filtered_df['Start Node'] != filtered_df['End Node']]\n",
    "        filtered_df.drop(\"reached_destination\", axis=1, inplace=True)\n",
    "        filtered_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        color_mapping = {node: G.nodes[node]['color'] for node in G.nodes()}\n",
    "        filtered_df['Mapped_Colors'] = filtered_df['Path'].apply(lambda path: [color_mapping[node] for node in path])\n",
    "        filtered_df['Path_Set'] = filtered_df['Path'].apply(lambda x: set(x))\n",
    "        \n",
    "        n = len(filtered_df)\n",
    "        distance_matrix = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                distance_matrix[i, j] = jaccard_distance(filtered_df.iloc[i]['Path_Set'], filtered_df.iloc[j]['Path_Set'])\n",
    "                distance_matrix[j, i] = distance_matrix[i, j]\n",
    "\n",
    "        distance_matrix_condensed = squareform(distance_matrix)\n",
    "        linkage_methods = ['single', 'complete', 'average', 'ward']\n",
    "        n_clusters = 2\n",
    "\n",
    "        for linkage_method in linkage_methods:\n",
    "            Z, clusters = hierarchical_clustering(distance_matrix_condensed, linkage_method, n_clusters)\n",
    "            filtered_df['Cluster'] = clusters\n",
    "            silhouette_avg = silhouette_score(distance_matrix, clusters, metric='precomputed')\n",
    "            results.append({\n",
    "                'Linkage Method': linkage_method,\n",
    "                'Seed': seed,\n",
    "                'Silhouette Score': silhouette_avg\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    best_method = results_df.groupby('Linkage Method')['Silhouette Score'].mean().idxmax()\n",
    "    best_score = results_df.groupby('Linkage Method')['Silhouette Score'].mean().max()\n",
    "\n",
    "    return best_method, best_score, results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e74647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import squareform\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2a2480",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m simulation_params \u001b[38;5;241m=\u001b[39m (num_agents, num_traversals)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Evaluate clustering methods\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m best_method, best_score, results_df \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_clustering_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulation_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Clustering Method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with Silhouette Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [3], line 169\u001b[0m, in \u001b[0;36mevaluate_clustering_methods\u001b[1;34m(num_seeds, graph_params, simulation_params)\u001b[0m\n\u001b[0;32m    167\u001b[0m         Z, clusters \u001b[38;5;241m=\u001b[39m hierarchical_clustering(distance_matrix_condensed, linkage_method, n_clusters)\n\u001b[0;32m    168\u001b[0m         filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clusters\n\u001b[1;32m--> 169\u001b[0m         silhouette_avg \u001b[38;5;241m=\u001b[39m \u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecomputed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinkage Method\u001b[39m\u001b[38;5;124m'\u001b[39m: linkage_method,\n\u001b[0;32m    172\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeed\u001b[39m\u001b[38;5;124m'\u001b[39m: seed,\n\u001b[0;32m    173\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSilhouette Score\u001b[39m\u001b[38;5;124m'\u001b[39m: silhouette_avg\n\u001b[0;32m    174\u001b[0m         })\n\u001b[0;32m    176\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:117\u001b[0m, in \u001b[0;36msilhouette_score\u001b[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(silhouette_samples(X, labels, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:231\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[1;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[0;32m    229\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[0;32m    230\u001b[0m label_freqs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(labels)\n\u001b[1;32m--> 231\u001b[0m \u001b[43mcheck_number_of_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[0;32m    234\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    235\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[0;32m    236\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:33\u001b[0m, in \u001b[0;36mcheck_number_of_labels\u001b[1;34m(n_labels, n_samples)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    Number of samples.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m n_labels \u001b[38;5;241m<\u001b[39m n_samples:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. Valid values are 2 to n_samples - 1 (inclusive)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;241m%\u001b[39m n_labels\n\u001b[0;32m     36\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "# Parameters for the graph generation\n",
    "num_nodes = 10\n",
    "colors = ['red', 'green']\n",
    "edge_probability = 0.9\n",
    "graph_params = (num_nodes, colors, edge_probability)\n",
    "\n",
    "# Parameters for the simulation\n",
    "num_agents = 5\n",
    "num_traversals = 20\n",
    "simulation_params = (num_agents, num_traversals)\n",
    "\n",
    "# Evaluate clustering methods\n",
    "best_method, best_score, results_df = evaluate_clustering_methods(50, graph_params, simulation_params)\n",
    "\n",
    "print(f\"Best Clustering Method: {best_method} with Silhouette Score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8b11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
