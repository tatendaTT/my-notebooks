{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12fffe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Simulation Phase (Agent V5 - Deterministic Preference, Structured Graph NO NOISE) ---\n",
      "\n",
      "Generating structured graph for Seed 0...\n",
      "  Assigning 40 nodes to 4 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 0...\n",
      " Starting simulations for Seed 0...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 0. Completed: 250, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 1...\n",
      "  Assigning 40 nodes to 4 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 1...\n",
      " Starting simulations for Seed 1...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 1. Completed: 250, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 2...\n",
      "  Assigning 40 nodes to 4 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 2...\n",
      " Starting simulations for Seed 2...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 2. Completed: 250, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 3...\n",
      "  Assigning 40 nodes to 4 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 3...\n",
      " Starting simulations for Seed 3...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 3. Completed: 250, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 4...\n",
      "  Assigning 40 nodes to 4 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 4...\n",
      " Starting simulations for Seed 4...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 4. Completed: 250, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 5...\n",
      "  Assigning 40 nodes to 4 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 5...\n",
      " Starting simulations for Seed 5...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 5. Completed: 250, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 6...\n",
      "  Assigning 40 nodes to 4 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 6...\n",
      " Starting simulations for Seed 6...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 6. Completed: 250, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 7...\n",
      "  Assigning 40 nodes to 4 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 7...\n",
      " Starting simulations for Seed 7...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 7. Completed: 250, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 8...\n",
      "  Assigning 40 nodes to 4 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 8...\n",
      " Starting simulations for Seed 8...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 8. Completed: 250, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 9...\n",
      "  Assigning 40 nodes to 4 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 9...\n",
      " Starting simulations for Seed 9...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 9. Completed: 250, Skipped: 0\n",
      "\n",
      "--- Simulation Phase Complete ---\n",
      "Generated 2500 records in 0.16s.\n",
      "\n",
      "--- Starting Clustering Phase ---\n",
      "\n",
      "--- Starting Clustering Evaluation ---\n",
      " Feature/Distance Method: boc\n",
      " Clustering Algorithm: kmeans\n",
      " Target Clusters (k): 4\n",
      " Processing Seed 0...\n",
      "  BoC Features extracted with shape: (250, 4)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n",
      " Processing Seed 1...\n",
      "  BoC Features extracted with shape: (250, 4)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n",
      " Processing Seed 2...\n",
      "  BoC Features extracted with shape: (250, 4)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n",
      " Processing Seed 3...\n",
      "  BoC Features extracted with shape: (250, 4)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n",
      " Processing Seed 4...\n",
      "  BoC Features extracted with shape: (250, 4)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n",
      " Processing Seed 5...\n",
      "  BoC Features extracted with shape: (250, 4)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n",
      " Processing Seed 6...\n",
      "  BoC Features extracted with shape: (250, 4)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n",
      " Processing Seed 7...\n",
      "  BoC Features extracted with shape: (250, 4)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n",
      " Processing Seed 8...\n",
      "  BoC Features extracted with shape: (250, 4)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n",
      " Processing Seed 9...\n",
      "  BoC Features extracted with shape: (250, 4)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n",
      "\n",
      "Clustering and evaluation complete.\n",
      "\n",
      "--- Clustering Phase Complete ---\n",
      "Completed in 0.78s.\n",
      "\n",
      "--- Clustering Summary Results ---\n",
      "   Seed Algorithm  Feature_Metric  Num_Clusters_Target  Num_Clusters_Found                                                                                                                                                                                                                                                                                                Cluster_Color_Percentage  Silhouette     ARI     NMI  Max_Color_Separation\n",
      "0     0    kmeans  boc(euclidean)                    4                   4     {1: {'blue': '77.94%', 'green': '5.88%', 'red': '7.94%', 'yellow': '8.24%'}, 2: {'blue': '10.05%', 'green': '9.52%', 'red': '11.31%', 'yellow': '69.12%'}, 3: {'blue': '7.54%', 'green': '81.01%', 'red': '4.75%', 'yellow': '6.70%'}, 4: {'blue': '7.54%', 'green': '10.22%', 'red': '75.43%', 'yellow': '6.81%'}}      0.7510  1.0000  1.0000               76.2570\n",
      "1     1    kmeans  boc(euclidean)                    4                   4     {1: {'blue': '9.16%', 'green': '9.42%', 'red': '73.30%', 'yellow': '8.12%'}, 2: {'blue': '8.04%', 'green': '75.89%', 'red': '8.48%', 'yellow': '7.59%'}, 3: {'blue': '81.31%', 'green': '8.01%', 'red': '5.58%', 'yellow': '5.10%'}, 4: {'blue': '13.75%', 'green': '11.67%', 'red': '13.12%', 'yellow': '61.46%'}}      0.7053  1.0000  1.0000               76.2136\n",
      "2     2    kmeans  boc(euclidean)                    4                   4       {1: {'blue': '9.45%', 'green': '9.45%', 'red': '11.29%', 'yellow': '69.82%'}, 2: {'blue': '6.82%', 'green': '81.02%', 'red': '8.10%', 'yellow': '4.05%'}, 3: {'blue': '77.78%', 'green': '7.78%', 'red': '6.39%', 'yellow': '8.06%'}, 4: {'blue': '6.91%', 'green': '8.51%', 'red': '76.06%', 'yellow': '8.51%'}}      0.7273  0.9900  0.9853               76.9723\n",
      "3     3    kmeans  boc(euclidean)                    4                   4      {1: {'blue': '9.87%', 'green': '9.32%', 'red': '10.60%', 'yellow': '70.20%'}, 2: {'blue': '10.25%', 'green': '9.50%', 'red': '71.50%', 'yellow': '8.75%'}, 3: {'blue': '83.33%', 'green': '4.80%', 'red': '7.06%', 'yellow': '4.80%'}, 4: {'blue': '6.34%', 'green': '81.57%', 'red': '5.74%', 'yellow': '6.34%'}}      0.7405  0.9904  0.9854               78.5311\n",
      "4     4    kmeans  boc(euclidean)                    4                   4     {1: {'blue': '80.65%', 'green': '5.38%', 'red': '8.60%', 'yellow': '5.38%'}, 2: {'blue': '11.00%', 'green': '72.61%', 'red': '8.92%', 'yellow': '7.47%'}, 3: {'blue': '5.22%', 'green': '5.22%', 'red': '6.96%', 'yellow': '82.61%'}, 4: {'blue': '14.35%', 'green': '12.06%', 'red': '65.49%', 'yellow': '8.11%'}}      0.7441  1.0000  1.0000               77.3913\n",
      "5     5    kmeans  boc(euclidean)                    4                   4  {1: {'blue': '68.13%', 'green': '9.89%', 'red': '9.45%', 'yellow': '12.53%'}, 2: {'blue': '11.22%', 'green': '11.02%', 'red': '68.37%', 'yellow': '9.39%'}, 3: {'blue': '7.60%', 'green': '5.64%', 'red': '9.56%', 'yellow': '77.21%'}, 4: {'blue': '12.95%', 'green': '61.57%', 'red': '12.74%', 'yellow': '12.74%'}}      0.6773  1.0000  1.0000               71.5686\n",
      "6     6    kmeans  boc(euclidean)                    4                   4    {1: {'blue': '6.55%', 'green': '73.41%', 'red': '8.93%', 'yellow': '11.11%'}, 2: {'blue': '5.21%', 'green': '7.06%', 'red': '85.89%', 'yellow': '1.84%'}, 3: {'blue': '60.89%', 'green': '11.81%', 'red': '13.84%', 'yellow': '13.47%'}, 4: {'blue': '7.02%', 'green': '7.89%', 'red': '6.14%', 'yellow': '78.95%'}}      0.7502  1.0000  1.0000               84.0491\n",
      "7     7    kmeans  boc(euclidean)                    4                   4      {1: {'blue': '6.32%', 'green': '5.85%', 'red': '5.85%', 'yellow': '81.97%'}, 2: {'blue': '74.61%', 'green': '8.90%', 'red': '11.78%', 'yellow': '4.71%'}, 3: {'blue': '8.58%', 'green': '8.58%', 'red': '72.30%', 'yellow': '10.54%'}, 4: {'blue': '6.73%', 'green': '79.80%', 'red': '5.74%', 'yellow': '7.73%'}}      0.7668  1.0000  1.0000               76.1124\n",
      "8     8    kmeans  boc(euclidean)                    4                   4   {1: {'blue': '9.65%', 'green': '7.77%', 'red': '10.19%', 'yellow': '72.39%'}, 2: {'blue': '9.90%', 'green': '62.86%', 'red': '14.48%', 'yellow': '12.76%'}, 3: {'blue': '84.81%', 'green': '3.80%', 'red': '5.06%', 'yellow': '6.33%'}, 4: {'blue': '9.37%', 'green': '11.33%', 'red': '68.63%', 'yellow': '10.68%'}}      0.7123  1.0000  1.0000               81.0127\n",
      "9     9    kmeans  boc(euclidean)                    4                   4    {1: {'blue': '7.27%', 'green': '6.27%', 'red': '11.28%', 'yellow': '75.19%'}, 2: {'blue': '9.88%', 'green': '68.93%', 'red': '10.70%', 'yellow': '10.49%'}, 3: {'blue': '6.75%', 'green': '4.82%', 'red': '81.99%', 'yellow': '6.43%'}, 4: {'blue': '72.29%', 'green': '10.84%', 'red': '8.84%', 'yellow': '8.03%'}}      0.7416  1.0000  1.0000               77.1704\n",
      "--------------------------------------------------\n",
      "Avg ARI: 0.9980\n",
      "Avg NMI: 0.9971\n",
      "Avg Silhouette: 0.7316\n",
      "--------------------------------------------------\n",
      "Summary results saved to clustering_results_boc_kmeans_agent_v5_explore_structured_NO_NOISE\\summary_boc_kmeans_k4_agent_v5_explore_structured_NO_NOISE.csv\n",
      "\n",
      "--- Remapping cluster labels for visualization ---\n",
      "  Majority Color per Original Cluster: {1: 'yellow', 2: 'green', 3: 'blue', 4: 'red'}\n",
      "  Cluster Remapping Dict (Original Cluster -> Target Plot Int): {1: 4, 2: 2, 3: 1, 4: 3}\n",
      "\n",
      "--- Generating Confusion Matrix (using REMAPPED cluster labels) ---\n",
      "\n",
      "--- Confusion Matrix Generation ---\n",
      " Using Color Mapping for Plot Axes: {'blue': 1, 'green': 2, 'red': 3, 'yellow': 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved confusion matrix plot to clustering_results_boc_kmeans_agent_v5_explore_structured_NO_NOISE\\plots_remapped\\confusion_matrix_Cluster_Remapped_vs_Color Preference.png\n",
      " Renamed plot to confusion_matrix_REORDERED_boc_kmeans_k4_agent_v5.png\n",
      "\n",
      "Pipeline finished.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Imports\n",
    "# ==============================================================================\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Set, Tuple, Any, Optional\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack as sparse_hstack\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# ==============================================================================\n",
    "# Agent Definition (Deterministic Preference + Explore Goal - Agent V5)\n",
    "# ==============================================================================\n",
    "# (Class Agent identical to previous version)\n",
    "class Agent:\n",
    "    \"\"\" Agent with Preference-Driven Goal: Find N preferred nodes using\n",
    "        Deterministic Preference strategy (always choose preferred if available). \"\"\"\n",
    "    def __init__(self, start_node: int, color_preference: str,\n",
    "                 target_preferred_count: int, max_steps: int):\n",
    "        self.start_node: int = start_node; self.color_preference: str = color_preference\n",
    "        self.target_preferred_count: int = target_preferred_count; self.max_steps: int = max_steps\n",
    "        self.current_node: int = start_node; self.visited_nodes: Set[int] = {start_node}\n",
    "        self.path: List[int] = [start_node]; self.preferred_nodes_visited: Set[int] = set()\n",
    "        self.visited_shapes: List[str] = []; self.visited_shininess: List[str] = []\n",
    "\n",
    "    def find_next_node(self, graph: nx.Graph, rng: random.Random) -> Optional[int]:\n",
    "        \"\"\" Determines next node using Deterministic Preference strategy (V5 logic). \"\"\"\n",
    "        neighbors = list(graph.neighbors(self.current_node)); unvisited_neighbors = [n for n in neighbors if n not in self.visited_nodes]\n",
    "        if not unvisited_neighbors: return None\n",
    "        # Use safe graph node access\n",
    "        preferred_unvisited_neighbors = [n for n in unvisited_neighbors if graph.nodes.get(n, {}).get('color') == self.color_preference]\n",
    "        if preferred_unvisited_neighbors: return rng.choice(preferred_unvisited_neighbors)\n",
    "        else: return rng.choice(unvisited_neighbors)\n",
    "\n",
    "    def traverse_graph(self, graph: nx.Graph, rng: random.Random) -> Tuple[List[int], int, int]:\n",
    "        \"\"\" Simulates exploration walk using deterministic preference strategy. \"\"\"\n",
    "        steps_taken = 0; self.preferred_nodes_visited = set()\n",
    "        try: # Record start node attributes safely\n",
    "            start_node_attrs = graph.nodes[self.start_node]; self.visited_shapes.append(start_node_attrs.get('shape', 'unknown')); self.visited_shininess.append(start_node_attrs.get('shiny', 'unknown'))\n",
    "            if start_node_attrs.get('color') == self.color_preference: self.preferred_nodes_visited.add(self.start_node)\n",
    "        except KeyError: self.visited_shapes.append('unknown'); self.visited_shininess.append('unknown')\n",
    "\n",
    "        while len(self.preferred_nodes_visited) < self.target_preferred_count and steps_taken < self.max_steps:\n",
    "            next_node = self.find_next_node(graph, rng) # Calls V5 logic\n",
    "            if next_node is None: break\n",
    "            self.visited_nodes.add(next_node); self.path.append(next_node); self.current_node = next_node; steps_taken += 1\n",
    "            try: # Record visited node attributes safely\n",
    "                node_attrs = graph.nodes[next_node]; self.visited_shapes.append(node_attrs.get('shape', 'unknown')); self.visited_shininess.append(node_attrs.get('shiny', 'unknown'))\n",
    "                if node_attrs.get('color') == self.color_preference: self.preferred_nodes_visited.add(next_node) # Add to set\n",
    "            except KeyError: self.visited_shapes.append('unknown'); self.visited_shininess.append('unknown')\n",
    "\n",
    "        preferred_nodes_found_count = len(self.preferred_nodes_visited)\n",
    "        return self.path, preferred_nodes_found_count, steps_taken\n",
    "\n",
    "# ==============================================================================\n",
    "# Graph Generation (Structured Version - Unchanged)\n",
    "# ==============================================================================\n",
    "# (Function generate_structured_colored_graph identical)\n",
    "def generate_structured_colored_graph(num_nodes: int, colors: List[str], edge_probability: float, structure_seed: int, edge_seed: int, noise_level: float = 0.1) -> nx.Graph:\n",
    "    G = nx.Graph(); num_colors = len(colors);\n",
    "    if num_colors == 0: raise ValueError(\"Color list empty.\");\n",
    "    if not 0.0 <= noise_level <= 1.0: raise ValueError(\"Noise level invalid.\")\n",
    "    nodes_per_region = num_nodes // num_colors; region_rng = random.Random(structure_seed); node_assignments = {}\n",
    "    nodes_list = list(range(1, num_nodes + 1)); region_rng.shuffle(nodes_list)\n",
    "    print(f\"  Assigning {num_nodes} nodes to {num_colors} color regions (Noise: {noise_level*100:.1f}%)...\")\n",
    "    for i, node_id in enumerate(nodes_list):\n",
    "        region_index = min(i // nodes_per_region, num_colors - 1); base_color = colors[region_index]; final_color = base_color\n",
    "        if noise_level > 0 and region_rng.random() < noise_level:\n",
    "            possible_noise_colors = [c for c in colors if c != base_color]\n",
    "            if possible_noise_colors: final_color = region_rng.choice(possible_noise_colors)\n",
    "        node_assignments[node_id] = final_color\n",
    "    shape_rng = random.Random(structure_seed + 1); shapes = ['circle', 'square', 'triangle']; shininess_options = ['shiny', 'not_shiny']\n",
    "    for i in range(1, num_nodes + 1):\n",
    "         shape = shape_rng.choice(shapes); shininess = shape_rng.choice(shininess_options)\n",
    "         G.add_node(i, color=node_assignments[i], shape=shape, shiny=shininess)\n",
    "    edge_rng = random.Random(edge_seed); edge_count = 0\n",
    "    for i in range(1, num_nodes + 1):\n",
    "        for j in range(i + 1, num_nodes + 1):\n",
    "            if edge_rng.random() < edge_probability: G.add_edge(i, j); edge_count += 1\n",
    "    if num_nodes > 0 and not nx.is_connected(G): warnings.warn(f\"Generated graph (seed {structure_seed}) not connected.\", stacklevel=2)\n",
    "    return G\n",
    "\n",
    "# ==============================================================================\n",
    "# Simulation (Preference-Driven Goal, Calls Agent V5)\n",
    "# ==============================================================================\n",
    "# (Function simulate_agents identical)\n",
    "def simulate_agents(graph: nx.Graph, num_agents: int, num_traversals_per_agent: int, simulation_seed: int, edge_probability: float, target_preferred_count: int, max_steps: int, colors_list: List[str] = ['blue', 'green', 'red', 'yellow']) -> pd.DataFrame:\n",
    "    agent_data = []; node_id_to_color_name = {node: graph.nodes[node].get('color', 'unknown') for node in graph.nodes()}\n",
    "    sim_rng = random.Random(simulation_seed); print(f\" Starting simulations for Seed {simulation_seed}...\")\n",
    "    total_simulations = num_agents * num_traversals_per_agent; completed_simulations = 0; skipped_simulations = 0\n",
    "    print(f\"  NOTE: Agent goal: Find {target_preferred_count} preferred nodes (max {max_steps} steps).\"); print(\"  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\");\n",
    "    nodes_list = list(graph.nodes())\n",
    "    if not nodes_list: print(\" Error: Graph has no nodes.\"); return pd.DataFrame(agent_data)\n",
    "    for i in range(total_simulations):\n",
    "        agent_id = i % num_agents; start_node = sim_rng.choice(nodes_list); color_preference = sim_rng.choice(colors_list)\n",
    "        agent = Agent(start_node, color_preference, target_preferred_count, max_steps)\n",
    "        try: path, preferred_nodes_found, steps_taken = agent.traverse_graph(graph, sim_rng); # No bias factor\n",
    "        except Exception as e: print(f\" Error during agent traversal call (Start: {start_node}, Pref: {color_preference}): {repr(e)}\"); skipped_simulations += 1; continue\n",
    "        if not path: print(f\"  Warning: Traversal returned empty path (Start: {start_node}). Skipping.\"); skipped_simulations += 1; continue\n",
    "        mapped_colors = [node_id_to_color_name.get(node, 'unknown') for node in agent.path]; path_len = len(agent.path); preferred_color_path_count = sum(1 for node in agent.path if graph.nodes.get(node, {}).get('color') == agent.color_preference); pref_prop = (preferred_color_path_count / path_len) if path_len > 0 else 0.0\n",
    "        agent_data.append({'Seed': simulation_seed, 'Agent': agent_id, 'Start Node': start_node, 'Color Preference': color_preference, 'Target Preferred Count': target_preferred_count, 'Max Steps': max_steps, 'Actual Steps Taken': steps_taken, 'Preferred Nodes Found': preferred_nodes_found, 'Path Length': path_len, 'Preferred Color Path Count': preferred_color_path_count, 'Preferred_Color_Proportion': pref_prop, 'Path': agent.path, 'Mapped Colors': mapped_colors, 'Visited Shapes': agent.visited_shapes, 'Visited Shininess': agent.visited_shininess, 'Density': edge_probability }); completed_simulations += 1\n",
    "    print(f\"  Finished simulations for Seed {simulation_seed}. Completed: {completed_simulations}, Skipped: {skipped_simulations}\")\n",
    "    return pd.DataFrame(agent_data)\n",
    "\n",
    "# ==============================================================================\n",
    "# Clustering Feature Engineering / Distance Calculation (Unchanged)\n",
    "# ==============================================================================\n",
    "# (Functions jaccard_distance, extract_boc_features, extract_combined_features, calculate_distance_matrix remain unchanged)\n",
    "# ... [Identical code as previous version for these functions] ...\n",
    "def jaccard_distance(set1: Any, set2: Any) -> float:\n",
    "    try: set1 = set(set1) if isinstance(set1, (list, tuple, np.ndarray)) else set(set1) if set1 is not None else set(); set2 = set(set2) if isinstance(set2, (list, tuple, np.ndarray)) else set(set2) if set2 is not None else set()\n",
    "    except TypeError: return 1.0\n",
    "    intersection = len(set1.intersection(set2)); union = len(set1.union(set2));\n",
    "    if union == 0: return 0.0\n",
    "    return 1.0 - intersection / union\n",
    "\n",
    "def extract_boc_features(group: pd.DataFrame) -> Optional[Any]:\n",
    "     if 'Mapped Colors' not in group.columns: print(\"Error:'Mapped Colors'\"); return None\n",
    "     corpus = group['Mapped Colors'].apply(lambda colors: ' '.join(map(str, colors)) if isinstance(colors, list) and colors else '')\n",
    "     try: vectorizer = CountVectorizer(); X = vectorizer.fit_transform(corpus); print(f\"  BoC Features extracted with shape: {X.shape}\"); return X\n",
    "     except Exception as e: print(f\"  Error extracting BoC features: {e}\"); return None\n",
    "\n",
    "def extract_combined_features(group: pd.DataFrame) -> Optional[Any]:\n",
    "    print(\"  Extracting Combined Features (BoC + Numerical)...\"); boc_features = extract_boc_features(group);\n",
    "    if boc_features is None: return None\n",
    "    num_cols = ['Path Length', 'Preferred_Color_Proportion'] # Ensure these cols exist\n",
    "    if not all(col in group.columns for col in num_cols): print(f\"Error: Missing {num_cols}\"); return None\n",
    "    try: numerical_features = group[num_cols].values.astype(float)\n",
    "    except Exception as e: print(f\"Error accessing numerical features: {e}\"); return None\n",
    "    try: scaler = StandardScaler(); scaled_numerical = scaler.fit_transform(numerical_features)\n",
    "    except Exception as e: print(f\"Error scaling numerical features: {e}\"); return None\n",
    "    try: combined_features = sparse_hstack((boc_features.tocsr(), scaled_numerical), format='csr'); print(f\"  Combined Features shape: {combined_features.shape}\"); return combined_features\n",
    "    except Exception as e: print(f\"Error combining features: {e}\"); return None\n",
    "\n",
    "def calculate_distance_matrix(group: pd.DataFrame, method: str = 'jaccard', **kwargs) -> Tuple[Optional[np.ndarray], Optional[Any], bool, str]:\n",
    "    num_samples = len(group); metric_used = method; distance_matrix = None; feature_matrix = None; is_valid = False\n",
    "    if method == 'jaccard':\n",
    "        metric_used = 'jaccard';\n",
    "        if 'Path' not in group.columns: print(\"Error:'Path'\"); return None, None, False, metric_used\n",
    "        group['Path_Set'] = group['Path'].apply(lambda x: set(x) if isinstance(x, (list, tuple)) else set())\n",
    "        distance_matrix_calc = np.zeros((num_samples, num_samples)); path_sets = group['Path_Set'].tolist()\n",
    "        for i in range(num_samples):\n",
    "            for j in range(i + 1, num_samples):\n",
    "                try: dist = jaccard_distance(path_sets[i], path_sets[j]);\n",
    "                except Exception as e: print(f\"Error Jaccard({i},{j}): {e}\"); return None, None, False, metric_used\n",
    "                if not np.isfinite(dist): raise ValueError(f\"Invalid Jaccard dist: {dist}\")\n",
    "                distance_matrix_calc[i, j] = dist; distance_matrix_calc[j, i] = dist\n",
    "        distance_matrix = distance_matrix_calc; is_valid = True\n",
    "    elif method == 'boc':\n",
    "        metric_used = kwargs.get('metric', 'cosine'); feature_matrix = extract_boc_features(group)\n",
    "        if feature_matrix is not None:\n",
    "            try: condensed_distances = pdist(feature_matrix.toarray(), metric=metric_used); distance_matrix = squareform(condensed_distances); print(f\"  BoC Features + '{metric_used}' distance matrix calculated.\"); is_valid = True\n",
    "            except Exception as e: print(f\"Warn: Could not create distance matrix from BoC: {e}\"); is_valid = True\n",
    "        else: return None, None, False, 'boc'\n",
    "    elif method == 'combined':\n",
    "         metric_used = kwargs.get('metric', 'euclidean'); feature_matrix = extract_combined_features(group)\n",
    "         if feature_matrix is not None: is_valid = True; distance_matrix = None; print(f\"  Combined features extracted. Assoc metric: '{metric_used}'\")\n",
    "         else: is_valid = False\n",
    "         return distance_matrix, feature_matrix, is_valid, metric_used\n",
    "    else: print(f\"Error: Unknown method '{method}'.\"); return None, None, False, 'unknown'\n",
    "    return distance_matrix, feature_matrix, is_valid, metric_used\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Clustering and Evaluation Function (Unchanged, includes fixes)\n",
    "# ==============================================================================\n",
    "# (Function cluster_and_evaluate remains identical)\n",
    "def cluster_and_evaluate(df: pd.DataFrame, n_clusters: int = 4, feature_distance_method: str = 'jaccard', cluster_method: str = 'ward', dist_metric_param: str = 'cosine', linkage_method: str = 'ward' ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # Adjust required cols check based on new simulation output if needed\n",
    "    required_cols = ['Seed', 'Color Preference', 'Mapped Colors'] # Base required\n",
    "    if feature_distance_method == 'jaccard': required_cols.append('Path')\n",
    "    elif feature_distance_method == 'combined': required_cols.extend(['Path Length', 'Preferred Color Path Count', 'Path', 'Mapped Colors'])\n",
    "    elif feature_distance_method == 'boc': required_cols.extend(['Path', 'Mapped Colors'])\n",
    "\n",
    "    if not all(col in df.columns for col in required_cols): raise ValueError(f\"Missing columns for eval: {required_cols}. Available: {df.columns.tolist()}\")\n",
    "    print(f\"\\n--- Starting Clustering Evaluation ---\"); print(f\" Feature/Distance Method: {feature_distance_method}\"); print(f\" Clustering Algorithm: {cluster_method}\"); print(f\" Target Clusters (k): {n_clusters}\")\n",
    "    results_summary = []; processed_groups = []\n",
    "    for seed, group in df.groupby('Seed'):\n",
    "        print(f\" Processing Seed {seed}...\"); group = group.copy(); num_samples = len(group); group['Cluster'] = -1\n",
    "        if num_samples < 2: print(f\"  Skipping Seed {seed}: Samples < 2.\"); processed_groups.append(group); continue\n",
    "        distance_matrix, feature_matrix, is_valid, eval_metric = calculate_distance_matrix(group, method=feature_distance_method, metric=dist_metric_param)\n",
    "        if not is_valid: processed_groups.append(group); continue\n",
    "        clusters = None; actual_n_clusters = min(n_clusters, num_samples) if num_samples > 0 else 1;\n",
    "        if actual_n_clusters < 1: actual_n_clusters = 1\n",
    "        try: # Clustering Block\n",
    "            if cluster_method in ['ward', 'complete', 'average', 'single']: # Hierarchical\n",
    "                 linkage_input_dm = distance_matrix\n",
    "                 if linkage_input_dm is None:\n",
    "                      if feature_matrix is not None:\n",
    "                           print(f\"  Calculating '{dist_metric_param}' distance matrix for hierarchical on features...\")\n",
    "                           try: linkage_input_dm = squareform(pdist(feature_matrix.toarray(), metric=dist_metric_param))\n",
    "                           except Exception as e_pdist: raise ValueError(f\"Failed distance calc for hierarchical: {e_pdist}\") from e_pdist\n",
    "                      else: raise ValueError(\"Neither distance matrix nor features available.\")\n",
    "                 if not isinstance(linkage_input_dm, np.ndarray) or linkage_input_dm.ndim!=2 or linkage_input_dm.shape[0]!=linkage_input_dm.shape[1]: raise ValueError(\"Invalid DM shape.\")\n",
    "                 if np.isnan(linkage_input_dm).any() or np.isinf(linkage_input_dm).any(): raise ValueError(\"NaN/Inf in DM.\")\n",
    "                 if not np.allclose(linkage_input_dm, linkage_input_dm.T): warnings.warn(f\"DM not symmetric (Seed {seed}).\", stacklevel=2); linkage_input_dm = (linkage_input_dm + linkage_input_dm.T) / 2\n",
    "                 np.fill_diagonal(linkage_input_dm, 0)\n",
    "                 try: condensed_distance = squareform(linkage_input_dm, checks=True)\n",
    "                 except ValueError as sq_err: raise ValueError(f\"Squareform check failed: {sq_err}\") from sq_err\n",
    "                 if condensed_distance is None or not np.isfinite(condensed_distance).all(): raise ValueError(\"Invalid condensed distance array.\")\n",
    "                 Z = linkage(condensed_distance, method=cluster_method);\n",
    "                 if Z is None or not isinstance(Z, np.ndarray): raise TypeError(\"Linkage failed.\")\n",
    "                 clusters = fcluster(Z, t=actual_n_clusters, criterion='maxclust')\n",
    "                 if clusters is None or not isinstance(clusters, np.ndarray): raise TypeError(\"fcluster failed.\")\n",
    "            elif cluster_method in ['kmeans', 'gmm']: # Feature-based\n",
    "                current_feature_matrix = feature_matrix\n",
    "                if current_feature_matrix is None:\n",
    "                     if feature_distance_method == 'boc': _, current_feature_matrix, _, _ = calculate_distance_matrix(group, 'boc', metric=dist_metric_param)\n",
    "                     elif feature_distance_method == 'combined': _, current_feature_matrix, _, _ = calculate_distance_matrix(group, 'combined', metric=dist_metric_param)\n",
    "                     if current_feature_matrix is None: raise ValueError(f\"Features required for {cluster_method}.\")\n",
    "                if cluster_method == 'kmeans': kmeans = KMeans(n_clusters=actual_n_clusters, random_state=seed, n_init=10, verbose=0); clusters = kmeans.fit_predict(current_feature_matrix); clusters += 1\n",
    "                elif cluster_method == 'gmm': gmm = GaussianMixture(n_components=actual_n_clusters, random_state=seed, verbose=0, n_init=5); clusters = gmm.fit_predict(current_feature_matrix.toarray()); clusters += 1\n",
    "            else: raise ValueError(f\"Unsupported cluster_method: {cluster_method}\")\n",
    "            group['Cluster'] = clusters; num_unique_clusters_found = len(set(c for c in clusters if c != -1))\n",
    "        except Exception as e: print(f\"  Error during clustering for Seed {seed}: {repr(e)}\"); processed_groups.append(group); continue\n",
    "        # --- Evaluation ---\n",
    "        silhouette_avg = np.nan; ari_score = np.nan; nmi_score = np.nan\n",
    "        valid_cluster_mask = group['Cluster'] != -1; clusters_for_eval = group.loc[valid_cluster_mask, 'Cluster']\n",
    "        num_valid_samples_for_eval = len(clusters_for_eval); num_clusters_for_eval = len(set(clusters_for_eval))\n",
    "        if num_clusters_for_eval > 1 and num_clusters_for_eval < num_valid_samples_for_eval: # Silhouette Calc\n",
    "            silhouette_input_data = None; silhouette_metric = 'euclidean' # Default\n",
    "            can_use_precomputed = (distance_matrix is not None)\n",
    "            if can_use_precomputed and (feature_distance_method == 'jaccard' or cluster_method in ['ward', 'complete', 'average', 'single']):\n",
    "                silhouette_metric = 'precomputed'; valid_mask_np = valid_cluster_mask.to_numpy()\n",
    "                if len(valid_mask_np) == distance_matrix.shape[0]:\n",
    "                     valid_distance_matrix = distance_matrix[np.ix_(valid_mask_np, valid_mask_np)]\n",
    "                     if valid_distance_matrix.shape[0] > 1:\n",
    "                         try: silhouette_avg = silhouette_score(valid_distance_matrix, clusters_for_eval, metric='precomputed')\n",
    "                         except Exception as e_sil: print(f\"   Warning: Silhouette (precomputed) error: {repr(e_sil)}\")\n",
    "                else: print(f\"   Warning: Index mismatch Silhouette submatrix (Seed {seed}).\")\n",
    "            elif feature_matrix is not None: # Try features\n",
    "                current_feature_matrix = feature_matrix\n",
    "                if current_feature_matrix.shape[0] == num_samples:\n",
    "                    valid_feature_matrix = current_feature_matrix[valid_cluster_mask]\n",
    "                    if valid_feature_matrix.shape[0] > 1:\n",
    "                        try: silhouette_avg = silhouette_score(valid_feature_matrix, clusters_for_eval, metric=eval_metric) # Use metric assoc. with features\n",
    "                        except Exception as e_sil: print(f\"   Warning: Silhouette (feature, metric='{eval_metric}') error: {repr(e_sil)}\")\n",
    "                else: print(f\"   Warning: Feature matrix shape mismatch Silhouette (Seed {seed}).\")\n",
    "            if silhouette_avg is np.nan and num_clusters_for_eval > 1:\n",
    "                 print(f\"   Skipping Silhouette: Input data invalid or unavailable (Seed {seed})\")\n",
    "        if num_valid_samples_for_eval > 0: # ARI/NMI Calc\n",
    "             try: true_labels_for_eval = group.loc[valid_cluster_mask, 'Color Preference']; ari_score = adjusted_rand_score(true_labels_for_eval, clusters_for_eval); nmi_score = normalized_mutual_info_score(true_labels_for_eval, clusters_for_eval)\n",
    "             except Exception as e_gnd: print(f\"   Warning: Could not compute ARI/NMI Seed {seed}: {repr(e_gnd)}\")\n",
    "        formatted_cluster_color_percentages = {}; max_color_separation = np.nan\n",
    "        try: # Purity Calc\n",
    "            valid_group_for_purity = group[group['Cluster'] != -1]\n",
    "            if not valid_group_for_purity.empty:\n",
    "                if 'Mapped Colors' in valid_group_for_purity.columns:\n",
    "                    exploded_group = valid_group_for_purity.explode('Mapped Colors').dropna(subset=['Mapped Colors']); exploded_group.rename(columns={'Mapped Colors': 'Flat Colors'}, inplace=True)\n",
    "                    color_counts = exploded_group.groupby(['Cluster', 'Flat Colors']).size().unstack(fill_value=0)\n",
    "                    all_possible_colors = sorted(df['Color Preference'].dropna().unique())\n",
    "                    for color in all_possible_colors:\n",
    "                        if color not in color_counts.columns: color_counts[color] = 0\n",
    "                    color_counts = color_counts[all_possible_colors]; cluster_sums = color_counts.sum(axis=1); safe_sums = cluster_sums.replace(0, 1)\n",
    "                    color_percentages = color_counts.div(safe_sums, axis=0).mul(100); cluster_color_percentages_dict = color_percentages.round(2).apply(lambda r: r.dropna().to_dict(), axis=1).to_dict()\n",
    "                    formatted_cluster_color_percentages = {int(k): {c: f\"{p:.2f}%\" for c, p in v.items()} for k, v in cluster_color_percentages_dict.items()}\n",
    "                    if not color_percentages.empty: max_color_separation = color_percentages.apply(lambda r: r.max() - r.min() if not r.empty else 0.0, axis=1).max()\n",
    "                    else: max_color_separation = 0.0\n",
    "                else: print(f\"   Warning: 'Mapped Colors' column missing for purity calc (Seed {seed}).\")\n",
    "        except Exception as e: print(f\"   Warning: Color percentage error Seed {seed}: {e}\")\n",
    "        results_summary.append({'Seed': seed, 'Algorithm': cluster_method, 'Feature_Metric': f\"{feature_distance_method}({eval_metric})\", 'Num_Clusters_Target': n_clusters, 'Num_Clusters_Found': num_clusters_for_eval, 'Cluster_Color_Percentage': formatted_cluster_color_percentages, 'Silhouette': silhouette_avg, 'ARI': ari_score, 'NMI': nmi_score, 'Max_Color_Separation': max_color_separation })\n",
    "        processed_groups.append(group)\n",
    "    if not processed_groups: warnings.warn(\"No groups processed.\"); return pd.DataFrame(results_summary), df.copy()\n",
    "    df_with_clusters = pd.concat(processed_groups).reset_index(drop=True); results_summary_df = pd.DataFrame(results_summary)\n",
    "    print(\"\\nClustering and evaluation complete.\")\n",
    "    return results_summary_df, df_with_clusters\n",
    "\n",
    "# ==============================================================================\n",
    "# Plotting Functions (Unchanged, includes SyntaxError Fix)\n",
    "# ==============================================================================\n",
    "# (plot_colored_graph and plot_color_confusion_matrix functions identical)\n",
    "def plot_colored_graph(G: nx.Graph, seed: int, output_dir: str = \"plots\"):\n",
    "    if not os.path.exists(output_dir): os.makedirs(output_dir); filepath = os.path.join(output_dir, f\"graph_seed_{seed}.png\")\n",
    "    plt.figure(figsize=(12, 10)); pos = nx.spring_layout(G, seed=42); node_colors = [G.nodes[node].get('color', 'gray') for node in G.nodes()]\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=200, alpha=0.9); nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
    "    plt.title(f\"Graph Structure (Seed {seed})\", fontsize=16); plt.axis('off'); plt.tight_layout(); plt.savefig(filepath); print(f\" Saved graph plot to {filepath}\"); plt.close()\n",
    "\n",
    "def plot_color_confusion_matrix(df: pd.DataFrame, cluster_col: str = 'Cluster', true_color_col: str = 'Color Preference', figsize: Tuple[int, int] = (8, 7), cmap: str = 'Blues', output_dir: str = \"plots\"):\n",
    "    # (No return value needed - just plots and saves)\n",
    "    if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "    plot_filename = f\"confusion_matrix_{cluster_col}_vs_{true_color_col}.png\"; filepath = os.path.join(output_dir, plot_filename)\n",
    "    # --- Input Validation (FIXED SyntaxError) ---\n",
    "    if cluster_col not in df.columns: raise ValueError(f\"Cluster column '{cluster_col}' not found.\")\n",
    "    if true_color_col not in df.columns: raise ValueError(f\"True color column '{true_color_col}' not found.\")\n",
    "    # --- End of Fix ---\n",
    "    df_valid = df[pd.to_numeric(df[cluster_col], errors='coerce').notna()].copy(); df_valid[cluster_col] = df_valid[cluster_col].astype(int); df_valid = df_valid[df_valid[cluster_col] > 0]\n",
    "    if df_valid.empty: print(\"Warning: No valid data for confusion matrix.\"); return\n",
    "    unique_colors = sorted(df_valid[true_color_col].dropna().unique());\n",
    "    if not unique_colors: print(f\"Error: No valid unique values in '{true_color_col}'.\"); return\n",
    "    color_to_int_mapping = {color: i + 1 for i, color in enumerate(unique_colors)}; mapped_color_ints = list(color_to_int_mapping.values()); mapped_color_names = list(color_to_int_mapping.keys())\n",
    "    print(f\"\\n--- Confusion Matrix Generation ---\"); print(f\" Using Color Mapping for Plot Axes: {color_to_int_mapping}\")\n",
    "    try: y_true = df_valid[true_color_col].map(color_to_int_mapping); y_pred = df_valid[cluster_col]\n",
    "    except Exception as e: print(f\" Error preparing y_true/y_pred: {e}\"); return\n",
    "    valid_indices = y_true.notna()\n",
    "    if not valid_indices.all(): y_true = y_true[valid_indices].astype(int); y_pred = y_pred[valid_indices]\n",
    "    if len(y_true) == 0: print(\" Error: No samples for confusion matrix.\"); return\n",
    "    matrix_labels_expected = mapped_color_ints; conf_matrix = confusion_matrix(y_true, y_pred, labels=matrix_labels_expected); conf_matrix_df = pd.DataFrame(conf_matrix, index=mapped_color_names, columns=mapped_color_names)\n",
    "    plt.figure(figsize=figsize); sns.heatmap(conf_matrix_df, annot=True, fmt='d', cmap=cmap, cbar=True, linewidths=.5, linecolor='lightgray', annot_kws={\"size\": 10})\n",
    "    plt.title('Confusion Matrix: Predicted Color (by Cluster) vs True Color', fontsize=14); plt.ylabel(f'True Color (`{true_color_col}`)', fontsize=12); plt.xlabel(f'Predicted Color (based on `{cluster_col}` Number)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10); plt.yticks(rotation=0, fontsize=10)\n",
    "    plt.tight_layout(); plt.savefig(filepath); print(f\" Saved confusion matrix plot to {filepath}\"); plt.close()\n",
    "    # Removed return statement\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Main Execution Block -> STRUCTURED GRAPH (NO NOISE) + EXPLORE AGENT (V5) + BOC/KMEANS\n",
    "# Includes Cluster Label Remapping for Plotting\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- Parameters ---\n",
    "    NUM_NODES = 40; COLORS = ['blue', 'green', 'red', 'yellow']; EDGE_PROBABILITY = 0.20\n",
    "    NUM_SEEDS = 10; NUM_AGENTS = 5; NUM_TRAVERSALS_PER_AGENT = 50; # -> 250 records per seed\n",
    "\n",
    "    # --- Simulation Parameters ---\n",
    "    TARGET_PREFERRED_COUNT = 5 # Agent goal\n",
    "    MAX_STEPS = 50             # Step limit\n",
    "    GRAPH_NOISE_LEVEL = 0.0 # <<< NO NOISE in structured graph >>>\n",
    "    # PREFERENCE_BIAS_FACTOR no longer needed for Agent V5\n",
    "\n",
    "    # --- Clustering Set to BOC + KMEANS ---\n",
    "    N_CLUSTERS = 4\n",
    "    FEATURE_DISTANCE_METHOD = 'boc'\n",
    "    CLUSTER_METHOD = 'kmeans'\n",
    "    DIST_METRIC = 'euclidean' # Metric for Silhouette when using BoC+KMeans features\n",
    "\n",
    "    # --- Output Directory ---\n",
    "    OUTPUT_DIR = f\"clustering_results_{FEATURE_DISTANCE_METHOD}_{CLUSTER_METHOD}_agent_v5_explore_structured_NO_NOISE\" # Updated name\n",
    "    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "    # --- Run Simulation (Agent V5 - Deterministic Preference, NO NOISE Structured Graph) ---\n",
    "    print(f\"--- Starting Simulation Phase (Agent V5 - Deterministic Preference, Structured Graph NO NOISE) ---\")\n",
    "    all_results_list = []; start_time_sim = time.time()\n",
    "    for seed in range(NUM_SEEDS):\n",
    "        graph_attribute_seed = seed; graph_edge_seed = seed + NUM_SEEDS\n",
    "        print(f\"\\nGenerating structured graph for Seed {seed}...\")\n",
    "        G = generate_structured_colored_graph(NUM_NODES, COLORS, EDGE_PROBABILITY,\n",
    "                                              graph_attribute_seed, graph_edge_seed,\n",
    "                                              noise_level=GRAPH_NOISE_LEVEL) # Pass 0.0\n",
    "        # plot_colored_graph(G, seed, output_dir=os.path.join(OUTPUT_DIR, \"graphs\")) # Optional\n",
    "        print(f\"Running Simulation for Seed {seed}...\")\n",
    "        simulation_seed = seed\n",
    "        df_agents = simulate_agents(G, NUM_AGENTS, NUM_TRAVERSALS_PER_AGENT,\n",
    "                                    simulation_seed, EDGE_PROBABILITY,\n",
    "                                    target_preferred_count=TARGET_PREFERRED_COUNT,\n",
    "                                    max_steps=MAX_STEPS,\n",
    "                                    colors_list=COLORS)\n",
    "        all_results_list.append(df_agents)\n",
    "    all_simulation_data = pd.concat(all_results_list, ignore_index=True); end_time_sim = time.time()\n",
    "    print(f\"\\n--- Simulation Phase Complete ---\"); print(f\"Generated {len(all_simulation_data)} records in {end_time_sim - start_time_sim:.2f}s.\")\n",
    "\n",
    "    # --- Run Clustering and Evaluation ---\n",
    "    print(f\"\\n--- Starting Clustering Phase ---\"); start_time_cluster = time.time()\n",
    "    summary_results, data_with_clusters = cluster_and_evaluate(\n",
    "        all_simulation_data.copy(),\n",
    "        n_clusters=N_CLUSTERS,\n",
    "        feature_distance_method=FEATURE_DISTANCE_METHOD, # 'boc'\n",
    "        cluster_method=CLUSTER_METHOD,                 # 'kmeans'\n",
    "        dist_metric_param=DIST_METRIC                  # 'euclidean'\n",
    "    )\n",
    "    end_time_cluster = time.time(); print(f\"\\n--- Clustering Phase Complete ---\"); print(f\"Completed in {end_time_cluster - start_time_cluster:.2f}s.\")\n",
    "\n",
    "    # --- Display and Save Results ---\n",
    "    print(\"\\n--- Clustering Summary Results ---\"); pd.set_option('display.max_rows', 50); pd.set_option('display.max_columns', None); pd.set_option('display.width', 120); pd.set_option('display.max_colwidth', 150)\n",
    "    if not summary_results.empty:\n",
    "        print(summary_results.round(4).to_string()); avg_ari = summary_results['ARI'].mean(); avg_nmi = summary_results['NMI'].mean(); avg_silhouette = summary_results['Silhouette'].mean()\n",
    "        print(\"-\" * 50); print(f\"Avg ARI: {avg_ari:.4f}\"); print(f\"Avg NMI: {avg_nmi:.4f}\"); print(f\"Avg Silhouette: {avg_silhouette:.4f}\"); print(\"-\" * 50)\n",
    "        summary_filename = f\"summary_{FEATURE_DISTANCE_METHOD}_{CLUSTER_METHOD}_k{N_CLUSTERS}_agent_v5_explore_structured_NO_NOISE.csv\"\n",
    "        summary_filepath = os.path.join(OUTPUT_DIR, summary_filename)\n",
    "        try: summary_results.to_csv(summary_filepath, index=False); print(f\"Summary results saved to {summary_filepath}\")\n",
    "        except Exception as e: print(f\"Error saving summary: {e}\")\n",
    "    else: print(\"No summary results generated.\")\n",
    "\n",
    "\n",
    "    # --- Generate and Save Confusion Matrix (with Remapping) ---\n",
    "    if not data_with_clusters.empty and 'Cluster' in data_with_clusters.columns and data_with_clusters['Cluster'].max() > 0 :\n",
    "         print(\"\\n--- Remapping cluster labels for visualization ---\")\n",
    "         # <<< START REMAPPING LOGIC >>>\n",
    "         try:\n",
    "             # Ensure we only use valid clusters for mapping calculation\n",
    "             valid_clusters_df = data_with_clusters[data_with_clusters['Cluster'] > 0].copy()\n",
    "\n",
    "             # Find the majority true label for each original cluster number\n",
    "             # Handle potential multiple modes by taking the first one (simple approach)\n",
    "             mode_map = valid_clusters_df.groupby('Cluster')['Color Preference'].agg(\n",
    "                 lambda x: x.mode()[0] if not x.empty and not x.mode().empty else None\n",
    "             ).to_dict()\n",
    "\n",
    "             # Find the desired integer mapping used by the plotting function (based on sorted unique true labels)\n",
    "             unique_colors = sorted(data_with_clusters['Color Preference'].dropna().unique())\n",
    "             true_color_to_plot_int = {color: i + 1 for i, color in enumerate(unique_colors)}\n",
    "\n",
    "             # Create the final remapping: original_cluster_num -> plot_int_representing_majority_color\n",
    "             remapping_dict = {}\n",
    "             assigned_plot_ints = set() # To check for conflicts\n",
    "             print(f\"  Majority Color per Original Cluster: {mode_map}\")\n",
    "\n",
    "             for original_cluster_num, majority_color_label in mode_map.items():\n",
    "                 if majority_color_label is not None:\n",
    "                     target_int = true_color_to_plot_int.get(majority_color_label)\n",
    "                     if target_int is not None:\n",
    "                         if target_int in assigned_plot_ints:\n",
    "                              warnings.warn(f\"Conflict: Cluster {original_cluster_num} also maps to '{majority_color_label}' (Int {target_int}), which was already assigned. Remapped matrix might not be perfectly diagonal.\", stacklevel=2)\n",
    "                         remapping_dict[original_cluster_num] = target_int\n",
    "                         assigned_plot_ints.add(target_int)\n",
    "                     else:\n",
    "                         print(f\"  Warning: Could not find target integer for majority color '{majority_color_label}' of cluster {original_cluster_num}\")\n",
    "                         remapping_dict[original_cluster_num] = -1 # Assign error label\n",
    "                 else:\n",
    "                      print(f\"  Warning: Cluster {original_cluster_num} was empty or had no mode.\")\n",
    "                      remapping_dict[original_cluster_num] = -1 # Assign error label\n",
    "\n",
    "             print(f\"  Cluster Remapping Dict (Original Cluster -> Target Plot Int): {remapping_dict}\")\n",
    "\n",
    "             # Apply the mapping to create a new column\n",
    "             data_with_clusters['Cluster_Remapped'] = data_with_clusters['Cluster'].map(remapping_dict).fillna(-1).astype(int)\n",
    "\n",
    "             # Plot using the remapped labels\n",
    "             print(\"\\n--- Generating Confusion Matrix (using REMAPPED cluster labels) ---\")\n",
    "             plot_output_dir = os.path.join(OUTPUT_DIR, \"plots_remapped\") # Use a different subdir\n",
    "             # Call plotting function using the NEW column name\n",
    "             plot_color_confusion_matrix(\n",
    "                 data_with_clusters,\n",
    "                 cluster_col='Cluster_Remapped', # <<< USE REMAPPED COLUMN\n",
    "                 true_color_col='Color Preference',\n",
    "                 output_dir=plot_output_dir\n",
    "             )\n",
    "             # Rename the saved plot file to indicate it's remapped\n",
    "             original_plot_name = f\"confusion_matrix_Cluster_Remapped_vs_Color Preference.png\"\n",
    "             new_plot_name = f\"confusion_matrix_REORDERED_{FEATURE_DISTANCE_METHOD}_{CLUSTER_METHOD}_k{N_CLUSTERS}_agent_v5.png\"\n",
    "             try:\n",
    "                 # Create dir if it doesn't exist\n",
    "                 if not os.path.exists(plot_output_dir): os.makedirs(plot_output_dir)\n",
    "                 os.rename(os.path.join(plot_output_dir, original_plot_name), os.path.join(plot_output_dir, new_plot_name))\n",
    "                 print(f\" Renamed plot to {new_plot_name}\")\n",
    "             except Exception as e_mv:\n",
    "                 print(f\" Could not rename remapped plot: {e_mv}\")\n",
    "\n",
    "         except NameError:\n",
    "             # This occurs if the plot function definition is missing\n",
    "             print(\"ERROR: plot_color_confusion_matrix function not defined.\")\n",
    "         except Exception as e:\n",
    "             print(f\"Could not remap labels or generate remapped confusion matrix plot: {e}\")\n",
    "         # <<< END REMAPPING LOGIC >>>\n",
    "\n",
    "    else: print(\"\\nSkipping confusion matrix plot.\")\n",
    "\n",
    "\n",
    "    # --- Optional: Save Full Data with Clusters ---\n",
    "    # detailed_filename = f\"data_with_clusters_{FEATURE_DISTANCE_METHOD}_{CLUSTER_METHOD}_k{N_CLUSTERS}_agent_v5_explore_structured_NO_NOISE.csv\"\n",
    "    # detailed_filepath = os.path.join(OUTPUT_DIR, detailed_filename)\n",
    "    # try: data_with_clusters.to_csv(detailed_filepath, index=False); print(f\"Detailed data saved to {detailed_filepath}\")\n",
    "    # except Exception as e: print(f\"Error saving detailed data: {e}\")\n",
    "\n",
    "    print(\"\\nPipeline finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8256721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
