{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6c77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Simulation Phase (Agent V5 - Deterministic Preference, Structured Graph NO NOISE) ---\n",
      "\n",
      "Generating structured graph for Seed 0...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 0...\n",
      " Starting simulations for Seed 0...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 0. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 1...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 1...\n",
      " Starting simulations for Seed 1...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 1. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 2...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 2...\n",
      " Starting simulations for Seed 2...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 2. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 3...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 3...\n",
      " Starting simulations for Seed 3...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 3. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 4...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 4...\n",
      " Starting simulations for Seed 4...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 4. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 5...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 5...\n",
      " Starting simulations for Seed 5...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 5. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 6...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 6...\n",
      " Starting simulations for Seed 6...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 6. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 7...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 7...\n",
      " Starting simulations for Seed 7...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 7. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 8...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 8...\n",
      " Starting simulations for Seed 8...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 8. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 9...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 9...\n",
      " Starting simulations for Seed 9...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 9. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 10...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 10...\n",
      " Starting simulations for Seed 10...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 10. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 11...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 11...\n",
      " Starting simulations for Seed 11...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 11. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 12...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 12...\n",
      " Starting simulations for Seed 12...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 12. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 13...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 13...\n",
      " Starting simulations for Seed 13...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 13. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 14...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 14...\n",
      " Starting simulations for Seed 14...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 14. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 15...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 15...\n",
      " Starting simulations for Seed 15...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 15. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 16...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 16...\n",
      " Starting simulations for Seed 16...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 16. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 17...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 17...\n",
      " Starting simulations for Seed 17...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 17. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 18...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 18...\n",
      " Starting simulations for Seed 18...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 18. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 19...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 19...\n",
      " Starting simulations for Seed 19...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 19. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 20...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 20...\n",
      " Starting simulations for Seed 20...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 20. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 21...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 21...\n",
      " Starting simulations for Seed 21...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 21. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 22...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 22...\n",
      " Starting simulations for Seed 22...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 22. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 23...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 23...\n",
      " Starting simulations for Seed 23...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 23. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 24...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 24...\n",
      " Starting simulations for Seed 24...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 24. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 25...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 25...\n",
      " Starting simulations for Seed 25...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 25. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 26...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 26...\n",
      " Starting simulations for Seed 26...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 26. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 27...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 27...\n",
      " Starting simulations for Seed 27...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 27. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 28...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 28...\n",
      " Starting simulations for Seed 28...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 28. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 29...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 29...\n",
      " Starting simulations for Seed 29...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 29. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 30...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 30...\n",
      " Starting simulations for Seed 30...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 30. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 31...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 31...\n",
      " Starting simulations for Seed 31...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 31. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 32...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 32...\n",
      " Starting simulations for Seed 32...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 32. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 33...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 33...\n",
      " Starting simulations for Seed 33...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 33. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 34...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 34...\n",
      " Starting simulations for Seed 34...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 34. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 35...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 35...\n",
      " Starting simulations for Seed 35...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 35. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 36...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 36...\n",
      " Starting simulations for Seed 36...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 36. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 37...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 37...\n",
      " Starting simulations for Seed 37...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 37. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 38...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 38...\n",
      " Starting simulations for Seed 38...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 38. Completed: 2000, Skipped: 0\n",
      "\n",
      "Generating structured graph for Seed 39...\n",
      "  Assigning 180 nodes to 6 color regions (Noise: 0.0%)...\n",
      "Running Simulation for Seed 39...\n",
      " Starting simulations for Seed 39...\n",
      "  NOTE: Agent goal: Find 5 preferred nodes (max 50 steps).\n",
      "  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\n",
      "  Finished simulations for Seed 39. Completed: 2000, Skipped: 0\n",
      "\n",
      "--- Simulation Phase Complete ---\n",
      "Generated 80000 records in 13.38s.\n",
      "\n",
      "--- Starting Clustering Phase ---\n",
      "\n",
      "--- Starting Clustering Evaluation ---\n",
      " Feature/Distance Method: boc\n",
      " Clustering Algorithm: kmeans\n",
      " Target Clusters (k): 6\n",
      " Processing Seed 0...\n",
      "  BoC Features extracted with shape: (2000, 5)\n",
      "  BoC Features + 'euclidean' distance matrix calculated.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'nonzero'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29052\\2213232947.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n--- Simulation Phase Complete ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Generated {len(all_simulation_data)} records in {end_time_sim - start_time_sim:.2f}s.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;31m# --- Run Clustering and Evaluation ---\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n--- Starting Clustering Phase ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mstart_time_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m     summary_results, data_with_clusters = cluster_and_evaluate(\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mall_simulation_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mN_CLUSTERS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mfeature_distance_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFEATURE_DISTANCE_METHOD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# 'boc'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29052\\2213232947.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df, n_clusters, feature_distance_method, cluster_method, dist_metric_param, linkage_method)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Warning: Index mismatch Silhouette submatrix (Seed {seed}).\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mfeature_matrix\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Try features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcurrent_feature_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcurrent_feature_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m                     \u001b[0mvalid_feature_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_feature_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_cluster_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mvalid_feature_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msilhouette_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_feature_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclusters_for_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Use metric assoc. with features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me_sil\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"   Warning: Silhouette (feature, metric='{eval_metric}') error: {repr(e_sil)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\py_project_env\\lib\\site-packages\\scipy\\sparse\\_index.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# 1D array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\py_project_env\\lib\\site-packages\\scipy\\sparse\\_index.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    279\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmid_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m                     raise IndexError(\n\u001b[0;32m    281\u001b[0m                         \u001b[1;34mf\"bool index {i} has shape {mid_shape} instead of {ix.shape}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                     )\n\u001b[1;32m--> 283\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m                 \u001b[0marray_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_ndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp_ndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[0mindex_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_ndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# dense array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\py_project_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'nonzero'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Majority Color per Original Cluster: {1: 'blue', 2: 'blue', 3: 'white', 4: 'green', 5: 'red', 6: 'blue'}\n",
      "  Cluster Remapping Dict (Original Cluster -> Target Plot Int): {1: 2, 2: 2, 3: 5, 4: 3, 5: 4, 6: 2}\n",
      "\n",
      "--- Generating Confusion Matrix (using REMAPPED cluster labels) ---\n",
      "\n",
      "--- Confusion Matrix Generation ---\n",
      " Using Color Mapping for Plot Axes: {'Blue': 1, 'blue': 2, 'green': 3, 'red': 4, 'white': 5, 'yellow': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taodz\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3378: UserWarning: Conflict: Cluster 2 also maps to 'blue' (Int 2), which was already assigned. Remapped matrix might not be perfectly diagonal.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\taodz\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3378: UserWarning: Conflict: Cluster 6 also maps to 'blue' (Int 2), which was already assigned. Remapped matrix might not be perfectly diagonal.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved confusion matrix plot to clustering_results_boc_kmeans_agent_v5_explore_structured_NO_NOISE\\plots_remapped\\confusion_matrix_Cluster_Remapped_vs_Color Preference.png\n",
      " Could not rename remapped plot: [WinError 183] Cannot create a file when that file already exists: 'clustering_results_boc_kmeans_agent_v5_explore_structured_NO_NOISE\\\\plots_remapped\\\\confusion_matrix_Cluster_Remapped_vs_Color Preference.png' -> 'clustering_results_boc_kmeans_agent_v5_explore_structured_NO_NOISE\\\\plots_remapped\\\\confusion_matrix_REORDERED_boc_kmeans_k6_agent_v5.png'\n",
      "\n",
      "Pipeline finished.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Imports\n",
    "# ==============================================================================\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Set, Tuple, Any, Optional\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack as sparse_hstack\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# ==============================================================================\n",
    "# Agent Definition (Deterministic Preference + Explore Goal - Agent V5)\n",
    "# ==============================================================================\n",
    "# (Class Agent identical to previous version)\n",
    "class Agent:\n",
    "    \"\"\" Agent with Preference-Driven Goal: Find N preferred nodes using\n",
    "        Deterministic Preference strategy (always choose preferred if available). \"\"\"\n",
    "    def __init__(self, start_node: int, color_preference: str,\n",
    "                 target_preferred_count: int, max_steps: int):\n",
    "        self.start_node: int = start_node; self.color_preference: str = color_preference\n",
    "        self.target_preferred_count: int = target_preferred_count; self.max_steps: int = max_steps\n",
    "        self.current_node: int = start_node; self.visited_nodes: Set[int] = {start_node}\n",
    "        self.path: List[int] = [start_node]; self.preferred_nodes_visited: Set[int] = set()\n",
    "        self.visited_shapes: List[str] = []; self.visited_shininess: List[str] = []\n",
    "\n",
    "    def find_next_node(self, graph: nx.Graph, rng: random.Random) -> Optional[int]:\n",
    "        \"\"\" Determines next node using Deterministic Preference strategy (V5 logic). \"\"\"\n",
    "        neighbors = list(graph.neighbors(self.current_node)); unvisited_neighbors = [n for n in neighbors if n not in self.visited_nodes]\n",
    "        if not unvisited_neighbors: return None\n",
    "        # Use safe graph node access\n",
    "        preferred_unvisited_neighbors = [n for n in unvisited_neighbors if graph.nodes.get(n, {}).get('color') == self.color_preference]\n",
    "        if preferred_unvisited_neighbors: return rng.choice(preferred_unvisited_neighbors)\n",
    "        else: return rng.choice(unvisited_neighbors)\n",
    "\n",
    "    def traverse_graph(self, graph: nx.Graph, rng: random.Random) -> Tuple[List[int], int, int]:\n",
    "        \"\"\" Simulates exploration walk using deterministic preference strategy. \"\"\"\n",
    "        steps_taken = 0; self.preferred_nodes_visited = set()\n",
    "        try: # Record start node attributes safely\n",
    "            start_node_attrs = graph.nodes[self.start_node]; self.visited_shapes.append(start_node_attrs.get('shape', 'unknown')); self.visited_shininess.append(start_node_attrs.get('shiny', 'unknown'))\n",
    "            if start_node_attrs.get('color') == self.color_preference: self.preferred_nodes_visited.add(self.start_node)\n",
    "        except KeyError: self.visited_shapes.append('unknown'); self.visited_shininess.append('unknown')\n",
    "\n",
    "        while len(self.preferred_nodes_visited) < self.target_preferred_count and steps_taken < self.max_steps:\n",
    "            next_node = self.find_next_node(graph, rng) # Calls V5 logic\n",
    "            if next_node is None: break\n",
    "            self.visited_nodes.add(next_node); self.path.append(next_node); self.current_node = next_node; steps_taken += 1\n",
    "            try: # Record visited node attributes safely\n",
    "                node_attrs = graph.nodes[next_node]; self.visited_shapes.append(node_attrs.get('shape', 'unknown')); self.visited_shininess.append(node_attrs.get('shiny', 'unknown'))\n",
    "                if node_attrs.get('color') == self.color_preference: self.preferred_nodes_visited.add(next_node) # Add to set\n",
    "            except KeyError: self.visited_shapes.append('unknown'); self.visited_shininess.append('unknown')\n",
    "\n",
    "        preferred_nodes_found_count = len(self.preferred_nodes_visited)\n",
    "        return self.path, preferred_nodes_found_count, steps_taken\n",
    "\n",
    "# ==============================================================================\n",
    "# Graph Generation \n",
    "# ==============================================================================\n",
    "\n",
    "def generate_structured_colored_graph(num_nodes: int, colors: List[str], edge_probability: float, structure_seed: int, edge_seed: int, noise_level: float = 0.1) -> nx.Graph:\n",
    "    G = nx.Graph(); num_colors = len(colors);\n",
    "    if num_colors == 0: raise ValueError(\"Color list empty.\");\n",
    "    if not 0.0 <= noise_level <= 1.0: raise ValueError(\"Noise level invalid.\")\n",
    "    nodes_per_region = num_nodes // num_colors; region_rng = random.Random(structure_seed); node_assignments = {}\n",
    "    nodes_list = list(range(1, num_nodes + 1)); region_rng.shuffle(nodes_list)\n",
    "    print(f\"  Assigning {num_nodes} nodes to {num_colors} color regions (Noise: {noise_level*100:.1f}%)...\")\n",
    "    for i, node_id in enumerate(nodes_list):\n",
    "        region_index = min(i // nodes_per_region, num_colors - 1); base_color = colors[region_index]; final_color = base_color\n",
    "        if noise_level > 0 and region_rng.random() < noise_level:\n",
    "            possible_noise_colors = [c for c in colors if c != base_color]\n",
    "            if possible_noise_colors: final_color = region_rng.choice(possible_noise_colors)\n",
    "        node_assignments[node_id] = final_color\n",
    "    shape_rng = random.Random(structure_seed + 1); shapes = ['circle', 'square', 'triangle']; shininess_options = ['shiny', 'not_shiny']\n",
    "    for i in range(1, num_nodes + 1):\n",
    "         shape = shape_rng.choice(shapes); shininess = shape_rng.choice(shininess_options)\n",
    "         G.add_node(i, color=node_assignments[i], shape=shape, shiny=shininess)\n",
    "    edge_rng = random.Random(edge_seed); edge_count = 0\n",
    "    for i in range(1, num_nodes + 1):\n",
    "        for j in range(i + 1, num_nodes + 1):\n",
    "            if edge_rng.random() < edge_probability: G.add_edge(i, j); edge_count += 1\n",
    "    if num_nodes > 0 and not nx.is_connected(G): warnings.warn(f\"Generated graph (seed {structure_seed}) not connected.\", stacklevel=2)\n",
    "    return G\n",
    "\n",
    "# ==============================================================================\n",
    "# Simulation (Preference-Driven Goal, Calls Agent V5)\n",
    "# ==============================================================================\n",
    "# (Function simulate_agents identical)\n",
    "def simulate_agents(graph: nx.Graph, num_agents: int, num_traversals_per_agent: int, simulation_seed: int, edge_probability: float, target_preferred_count: int, max_steps: int, colors_list: List[str] = ['blue', 'green', 'red', 'yellow']) -> pd.DataFrame:\n",
    "    agent_data = []; node_id_to_color_name = {node: graph.nodes[node].get('color', 'unknown') for node in graph.nodes()}\n",
    "    sim_rng = random.Random(simulation_seed); print(f\" Starting simulations for Seed {simulation_seed}...\")\n",
    "    total_simulations = num_agents * num_traversals_per_agent; completed_simulations = 0; skipped_simulations = 0\n",
    "    print(f\"  NOTE: Agent goal: Find {target_preferred_count} preferred nodes (max {max_steps} steps).\"); print(\"  NOTE: Agent using DETERMINISTIC PREFERENCE strategy.\");\n",
    "    nodes_list = list(graph.nodes())\n",
    "    if not nodes_list: print(\" Error: Graph has no nodes.\"); return pd.DataFrame(agent_data)\n",
    "    for i in range(total_simulations):\n",
    "        agent_id = i % num_agents; start_node = sim_rng.choice(nodes_list); color_preference = sim_rng.choice(colors_list)\n",
    "        agent = Agent(start_node, color_preference, target_preferred_count, max_steps)\n",
    "        try: path, preferred_nodes_found, steps_taken = agent.traverse_graph(graph, sim_rng); # No bias factor\n",
    "        except Exception as e: print(f\" Error during agent traversal call (Start: {start_node}, Pref: {color_preference}): {repr(e)}\"); skipped_simulations += 1; continue\n",
    "        if not path: print(f\"  Warning: Traversal returned empty path (Start: {start_node}). Skipping.\"); skipped_simulations += 1; continue\n",
    "        mapped_colors = [node_id_to_color_name.get(node, 'unknown') for node in agent.path]; path_len = len(agent.path); preferred_color_path_count = sum(1 for node in agent.path if graph.nodes.get(node, {}).get('color') == agent.color_preference); pref_prop = (preferred_color_path_count / path_len) if path_len > 0 else 0.0\n",
    "        agent_data.append({'Seed': simulation_seed, 'Agent': agent_id, 'Start Node': start_node, 'Color Preference': color_preference, 'Target Preferred Count': target_preferred_count, 'Max Steps': max_steps, 'Actual Steps Taken': steps_taken, 'Preferred Nodes Found': preferred_nodes_found, 'Path Length': path_len, 'Preferred Color Path Count': preferred_color_path_count, 'Preferred_Color_Proportion': pref_prop, 'Path': agent.path, 'Mapped Colors': mapped_colors, 'Visited Shapes': agent.visited_shapes, 'Visited Shininess': agent.visited_shininess, 'Density': edge_probability }); completed_simulations += 1\n",
    "    print(f\"  Finished simulations for Seed {simulation_seed}. Completed: {completed_simulations}, Skipped: {skipped_simulations}\")\n",
    "    return pd.DataFrame(agent_data)\n",
    "\n",
    "# ==============================================================================\n",
    "# Clustering Feature Engineering / Distance Calculation \n",
    "# ==============================================================================\n",
    "\n",
    "def jaccard_distance(set1: Any, set2: Any) -> float:\n",
    "    try: set1 = set(set1) if isinstance(set1, (list, tuple, np.ndarray)) else set(set1) if set1 is not None else set(); set2 = set(set2) if isinstance(set2, (list, tuple, np.ndarray)) else set(set2) if set2 is not None else set()\n",
    "    except TypeError: return 1.0\n",
    "    intersection = len(set1.intersection(set2)); union = len(set1.union(set2));\n",
    "    if union == 0: return 0.0\n",
    "    return 1.0 - intersection / union\n",
    "\n",
    "def extract_boc_features(group: pd.DataFrame) -> Optional[Any]:\n",
    "     if 'Mapped Colors' not in group.columns: print(\"Error:'Mapped Colors'\"); return None\n",
    "     corpus = group['Mapped Colors'].apply(lambda colors: ' '.join(map(str, colors)) if isinstance(colors, list) and colors else '')\n",
    "     try: vectorizer = CountVectorizer(); X = vectorizer.fit_transform(corpus); print(f\"  BoC Features extracted with shape: {X.shape}\"); return X\n",
    "     except Exception as e: print(f\"  Error extracting BoC features: {e}\"); return None\n",
    "\n",
    "def extract_combined_features(group: pd.DataFrame) -> Optional[Any]:\n",
    "    print(\"  Extracting Combined Features (BoC + Numerical)...\"); boc_features = extract_boc_features(group);\n",
    "    if boc_features is None: return None\n",
    "    num_cols = ['Path Length', 'Preferred_Color_Proportion'] # these cols exist\n",
    "    if not all(col in group.columns for col in num_cols): print(f\"Error: Missing {num_cols}\"); return None\n",
    "    try: numerical_features = group[num_cols].values.astype(float)\n",
    "    except Exception as e: print(f\"Error accessing numerical features: {e}\"); return None\n",
    "    try: scaler = StandardScaler(); scaled_numerical = scaler.fit_transform(numerical_features)\n",
    "    except Exception as e: print(f\"Error scaling numerical features: {e}\"); return None\n",
    "    try: combined_features = sparse_hstack((boc_features.tocsr(), scaled_numerical), format='csr'); print(f\"  Combined Features shape: {combined_features.shape}\"); return combined_features\n",
    "    except Exception as e: print(f\"Error combining features: {e}\"); return None\n",
    "\n",
    "def calculate_distance_matrix(group: pd.DataFrame, method: str = 'jaccard', **kwargs) -> Tuple[Optional[np.ndarray], Optional[Any], bool, str]:\n",
    "    num_samples = len(group); metric_used = method; distance_matrix = None; feature_matrix = None; is_valid = False\n",
    "    if method == 'jaccard':\n",
    "        metric_used = 'jaccard';\n",
    "        if 'Path' not in group.columns: print(\"Error:'Path'\"); return None, None, False, metric_used\n",
    "        group['Path_Set'] = group['Path'].apply(lambda x: set(x) if isinstance(x, (list, tuple)) else set())\n",
    "        distance_matrix_calc = np.zeros((num_samples, num_samples)); path_sets = group['Path_Set'].tolist()\n",
    "        for i in range(num_samples):\n",
    "            for j in range(i + 1, num_samples):\n",
    "                try: dist = jaccard_distance(path_sets[i], path_sets[j]);\n",
    "                except Exception as e: print(f\"Error Jaccard({i},{j}): {e}\"); return None, None, False, metric_used\n",
    "                if not np.isfinite(dist): raise ValueError(f\"Invalid Jaccard dist: {dist}\")\n",
    "                distance_matrix_calc[i, j] = dist; distance_matrix_calc[j, i] = dist\n",
    "        distance_matrix = distance_matrix_calc; is_valid = True\n",
    "    elif method == 'boc':\n",
    "        metric_used = kwargs.get('metric', 'cosine'); feature_matrix = extract_boc_features(group)\n",
    "        if feature_matrix is not None:\n",
    "            try: condensed_distances = pdist(feature_matrix.toarray(), metric=metric_used); distance_matrix = squareform(condensed_distances); print(f\"  BoC Features + '{metric_used}' distance matrix calculated.\"); is_valid = True\n",
    "            except Exception as e: print(f\"Warn: Could not create distance matrix from BoC: {e}\"); is_valid = True\n",
    "        else: return None, None, False, 'boc'\n",
    "    elif method == 'combined':\n",
    "         metric_used = kwargs.get('metric', 'euclidean'); feature_matrix = extract_combined_features(group)\n",
    "         if feature_matrix is not None: is_valid = True; distance_matrix = None; print(f\"  Combined features extracted. Assoc metric: '{metric_used}'\")\n",
    "         else: is_valid = False\n",
    "         return distance_matrix, feature_matrix, is_valid, metric_used\n",
    "    else: print(f\"Error: Unknown method '{method}'.\"); return None, None, False, 'unknown'\n",
    "    return distance_matrix, feature_matrix, is_valid, metric_used\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Clustering and Evaluation Function (Unchanged, includes fixes)\n",
    "# ==============================================================================\n",
    "def cluster_and_evaluate(df: pd.DataFrame, n_clusters: int = 4, feature_distance_method: str = 'jaccard', cluster_method: str = 'ward', dist_metric_param: str = 'cosine', linkage_method: str = 'ward' ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    required_cols = ['Seed', 'Color Preference', 'Mapped Colors'] \n",
    "    if feature_distance_method == 'jaccard': required_cols.append('Path')\n",
    "    elif feature_distance_method == 'combined': required_cols.extend(['Path Length', 'Preferred Color Path Count', 'Path', 'Mapped Colors'])\n",
    "    elif feature_distance_method == 'boc': required_cols.extend(['Path', 'Mapped Colors'])\n",
    "\n",
    "    if not all(col in df.columns for col in required_cols): raise ValueError(f\"Missing columns for eval: {required_cols}. Available: {df.columns.tolist()}\")\n",
    "    print(f\"\\n--- Starting Clustering Evaluation ---\"); print(f\" Feature/Distance Method: {feature_distance_method}\"); print(f\" Clustering Algorithm: {cluster_method}\"); print(f\" Target Clusters (k): {n_clusters}\")\n",
    "    results_summary = []; processed_groups = []\n",
    "    for seed, group in df.groupby('Seed'):\n",
    "        print(f\" Processing Seed {seed}...\"); group = group.copy(); num_samples = len(group); group['Cluster'] = -1\n",
    "        if num_samples < 2: print(f\"  Skipping Seed {seed}: Samples < 2.\"); processed_groups.append(group); continue\n",
    "        distance_matrix, feature_matrix, is_valid, eval_metric = calculate_distance_matrix(group, method=feature_distance_method, metric=dist_metric_param)\n",
    "        if not is_valid: processed_groups.append(group); continue\n",
    "        clusters = None; actual_n_clusters = min(n_clusters, num_samples) if num_samples > 0 else 1;\n",
    "        if actual_n_clusters < 1: actual_n_clusters = 1\n",
    "        try: # Clustering Block\n",
    "            if cluster_method in ['ward', 'complete', 'average', 'single']: # Hierarchical\n",
    "                 linkage_input_dm = distance_matrix\n",
    "                 if linkage_input_dm is None:\n",
    "                      if feature_matrix is not None:\n",
    "                           print(f\"  Calculating '{dist_metric_param}' distance matrix for hierarchical on features...\")\n",
    "                           try: linkage_input_dm = squareform(pdist(feature_matrix.toarray(), metric=dist_metric_param))\n",
    "                           except Exception as e_pdist: raise ValueError(f\"Failed distance calc for hierarchical: {e_pdist}\") from e_pdist\n",
    "                      else: raise ValueError(\"Neither distance matrix nor features available.\")\n",
    "                 if not isinstance(linkage_input_dm, np.ndarray) or linkage_input_dm.ndim!=2 or linkage_input_dm.shape[0]!=linkage_input_dm.shape[1]: raise ValueError(\"Invalid DM shape.\")\n",
    "                 if np.isnan(linkage_input_dm).any() or np.isinf(linkage_input_dm).any(): raise ValueError(\"NaN/Inf in DM.\")\n",
    "                 if not np.allclose(linkage_input_dm, linkage_input_dm.T): warnings.warn(f\"DM not symmetric (Seed {seed}).\", stacklevel=2); linkage_input_dm = (linkage_input_dm + linkage_input_dm.T) / 2\n",
    "                 np.fill_diagonal(linkage_input_dm, 0)\n",
    "                 try: condensed_distance = squareform(linkage_input_dm, checks=True)\n",
    "                 except ValueError as sq_err: raise ValueError(f\"Squareform check failed: {sq_err}\") from sq_err\n",
    "                 if condensed_distance is None or not np.isfinite(condensed_distance).all(): raise ValueError(\"Invalid condensed distance array.\")\n",
    "                 Z = linkage(condensed_distance, method=cluster_method);\n",
    "                 if Z is None or not isinstance(Z, np.ndarray): raise TypeError(\"Linkage failed.\")\n",
    "                 clusters = fcluster(Z, t=actual_n_clusters, criterion='maxclust')\n",
    "                 if clusters is None or not isinstance(clusters, np.ndarray): raise TypeError(\"fcluster failed.\")\n",
    "            elif cluster_method in ['kmeans', 'gmm']: # Feature-based\n",
    "                current_feature_matrix = feature_matrix\n",
    "                if current_feature_matrix is None:\n",
    "                     if feature_distance_method == 'boc': _, current_feature_matrix, _, _ = calculate_distance_matrix(group, 'boc', metric=dist_metric_param)\n",
    "                     elif feature_distance_method == 'combined': _, current_feature_matrix, _, _ = calculate_distance_matrix(group, 'combined', metric=dist_metric_param)\n",
    "                     if current_feature_matrix is None: raise ValueError(f\"Features required for {cluster_method}.\")\n",
    "                if cluster_method == 'kmeans': kmeans = KMeans(n_clusters=actual_n_clusters, random_state=seed, n_init=10, verbose=0); clusters = kmeans.fit_predict(current_feature_matrix); clusters += 1\n",
    "                elif cluster_method == 'gmm': gmm = GaussianMixture(n_components=actual_n_clusters, random_state=seed, verbose=0, n_init=5); clusters = gmm.fit_predict(current_feature_matrix.toarray()); clusters += 1\n",
    "            else: raise ValueError(f\"Unsupported cluster_method: {cluster_method}\")\n",
    "            group['Cluster'] = clusters; num_unique_clusters_found = len(set(c for c in clusters if c != -1))\n",
    "        except Exception as e: print(f\"  Error during clustering for Seed {seed}: {repr(e)}\"); processed_groups.append(group); continue\n",
    "        # --- Evaluation ---\n",
    "        silhouette_avg = np.nan; ari_score = np.nan; nmi_score = np.nan\n",
    "        valid_cluster_mask = group['Cluster'] != -1; clusters_for_eval = group.loc[valid_cluster_mask, 'Cluster']\n",
    "        num_valid_samples_for_eval = len(clusters_for_eval); num_clusters_for_eval = len(set(clusters_for_eval))\n",
    "        if num_clusters_for_eval > 1 and num_clusters_for_eval < num_valid_samples_for_eval: # Silhouette Calc\n",
    "            silhouette_input_data = None; silhouette_metric = 'euclidean' # Default\n",
    "            can_use_precomputed = (distance_matrix is not None)\n",
    "            if can_use_precomputed and (feature_distance_method == 'jaccard' or cluster_method in ['ward', 'complete', 'average', 'single']):\n",
    "                silhouette_metric = 'precomputed'; valid_mask_np = valid_cluster_mask.to_numpy()\n",
    "                if len(valid_mask_np) == distance_matrix.shape[0]:\n",
    "                     valid_distance_matrix = distance_matrix[np.ix_(valid_mask_np, valid_mask_np)]\n",
    "                     if valid_distance_matrix.shape[0] > 1:\n",
    "                         try: silhouette_avg = silhouette_score(valid_distance_matrix, clusters_for_eval, metric='precomputed')\n",
    "                         except Exception as e_sil: print(f\"   Warning: Silhouette (precomputed) error: {repr(e_sil)}\")\n",
    "                else: print(f\"   Warning: Index mismatch Silhouette submatrix (Seed {seed}).\")\n",
    "            elif feature_matrix is not None: # Try features\n",
    "                current_feature_matrix = feature_matrix\n",
    "                if current_feature_matrix.shape[0] == num_samples:\n",
    "                    valid_feature_matrix = current_feature_matrix[valid_cluster_mask]\n",
    "                    if valid_feature_matrix.shape[0] > 1:\n",
    "                        try: silhouette_avg = silhouette_score(valid_feature_matrix, clusters_for_eval, metric=eval_metric) # Use metric assoc. with features\n",
    "                        except Exception as e_sil: print(f\"   Warning: Silhouette (feature, metric='{eval_metric}') error: {repr(e_sil)}\")\n",
    "                else: print(f\"   Warning: Feature matrix shape mismatch Silhouette (Seed {seed}).\")\n",
    "            if silhouette_avg is np.nan and num_clusters_for_eval > 1:\n",
    "                 print(f\"   Skipping Silhouette: Input data invalid or unavailable (Seed {seed})\")\n",
    "        if num_valid_samples_for_eval > 0: # ARI/NMI Calc\n",
    "             try: true_labels_for_eval = group.loc[valid_cluster_mask, 'Color Preference']; ari_score = adjusted_rand_score(true_labels_for_eval, clusters_for_eval); nmi_score = normalized_mutual_info_score(true_labels_for_eval, clusters_for_eval)\n",
    "             except Exception as e_gnd: print(f\"   Warning: Could not compute ARI/NMI Seed {seed}: {repr(e_gnd)}\")\n",
    "        formatted_cluster_color_percentages = {}; max_color_separation = np.nan\n",
    "        try: # Purity Calc\n",
    "            valid_group_for_purity = group[group['Cluster'] != -1]\n",
    "            if not valid_group_for_purity.empty:\n",
    "                if 'Mapped Colors' in valid_group_for_purity.columns:\n",
    "                    exploded_group = valid_group_for_purity.explode('Mapped Colors').dropna(subset=['Mapped Colors']); exploded_group.rename(columns={'Mapped Colors': 'Flat Colors'}, inplace=True)\n",
    "                    color_counts = exploded_group.groupby(['Cluster', 'Flat Colors']).size().unstack(fill_value=0)\n",
    "                    all_possible_colors = sorted(df['Color Preference'].dropna().unique())\n",
    "                    for color in all_possible_colors:\n",
    "                        if color not in color_counts.columns: color_counts[color] = 0\n",
    "                    color_counts = color_counts[all_possible_colors]; cluster_sums = color_counts.sum(axis=1); safe_sums = cluster_sums.replace(0, 1)\n",
    "                    color_percentages = color_counts.div(safe_sums, axis=0).mul(100); cluster_color_percentages_dict = color_percentages.round(2).apply(lambda r: r.dropna().to_dict(), axis=1).to_dict()\n",
    "                    formatted_cluster_color_percentages = {int(k): {c: f\"{p:.2f}%\" for c, p in v.items()} for k, v in cluster_color_percentages_dict.items()}\n",
    "                    if not color_percentages.empty: max_color_separation = color_percentages.apply(lambda r: r.max() - r.min() if not r.empty else 0.0, axis=1).max()\n",
    "                    else: max_color_separation = 0.0\n",
    "                else: print(f\"   Warning: 'Mapped Colors' column missing for purity calc (Seed {seed}).\")\n",
    "        except Exception as e: print(f\"   Warning: Color percentage error Seed {seed}: {e}\")\n",
    "        results_summary.append({'Seed': seed, 'Algorithm': cluster_method, 'Feature_Metric': f\"{feature_distance_method}({eval_metric})\", 'Num_Clusters_Target': n_clusters, 'Num_Clusters_Found': num_clusters_for_eval, 'Cluster_Color_Percentage': formatted_cluster_color_percentages, 'Silhouette': silhouette_avg, 'ARI': ari_score, 'NMI': nmi_score, 'Max_Color_Separation': max_color_separation })\n",
    "        processed_groups.append(group)\n",
    "    if not processed_groups: warnings.warn(\"No groups processed.\"); return pd.DataFrame(results_summary), df.copy()\n",
    "    df_with_clusters = pd.concat(processed_groups).reset_index(drop=True); results_summary_df = pd.DataFrame(results_summary)\n",
    "    print(\"\\nClustering and evaluation complete.\")\n",
    "    return results_summary_df, df_with_clusters\n",
    "\n",
    "# ==============================================================================\n",
    "# Plotting Functions (Unchanged, includes SyntaxError Fix)\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_colored_graph(G: nx.Graph, seed: int, output_dir: str = \"plots\"):\n",
    "    if not os.path.exists(output_dir): os.makedirs(output_dir); filepath = os.path.join(output_dir, f\"graph_seed_{seed}.png\")\n",
    "    plt.figure(figsize=(12, 10)); pos = nx.spring_layout(G, seed=42); node_colors = [G.nodes[node].get('color', 'gray') for node in G.nodes()]\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=200, alpha=0.9); nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
    "    plt.title(f\"Graph Structure (Seed {seed})\", fontsize=16); plt.axis('off'); plt.tight_layout(); plt.savefig(filepath); print(f\" Saved graph plot to {filepath}\"); plt.close()\n",
    "\n",
    "def plot_color_confusion_matrix(df: pd.DataFrame, cluster_col: str = 'Cluster', true_color_col: str = 'Color Preference', figsize: Tuple[int, int] = (8, 7), cmap: str = 'Blues', output_dir: str = \"plots\"):\n",
    "    # (No return value needed - just plots and saves)\n",
    "    if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "    plot_filename = f\"confusion_matrix_{cluster_col}_vs_{true_color_col}.png\"; filepath = os.path.join(output_dir, plot_filename)\n",
    "    # --- Input Validation \n",
    "    if cluster_col not in df.columns: raise ValueError(f\"Cluster column '{cluster_col}' not found.\")\n",
    "    if true_color_col not in df.columns: raise ValueError(f\"True color column '{true_color_col}' not found.\")\n",
    "    # --- End of Fix ---\n",
    "    df_valid = df[pd.to_numeric(df[cluster_col], errors='coerce').notna()].copy(); df_valid[cluster_col] = df_valid[cluster_col].astype(int); df_valid = df_valid[df_valid[cluster_col] > 0]\n",
    "    if df_valid.empty: print(\"Warning: No valid data for confusion matrix.\"); return\n",
    "    unique_colors = sorted(df_valid[true_color_col].dropna().unique());\n",
    "    if not unique_colors: print(f\"Error: No valid unique values in '{true_color_col}'.\"); return\n",
    "    color_to_int_mapping = {color: i + 1 for i, color in enumerate(unique_colors)}; mapped_color_ints = list(color_to_int_mapping.values()); mapped_color_names = list(color_to_int_mapping.keys())\n",
    "    print(f\"\\n--- Confusion Matrix Generation ---\"); print(f\" Using Color Mapping for Plot Axes: {color_to_int_mapping}\")\n",
    "    try: y_true = df_valid[true_color_col].map(color_to_int_mapping); y_pred = df_valid[cluster_col]\n",
    "    except Exception as e: print(f\" Error preparing y_true/y_pred: {e}\"); return\n",
    "    valid_indices = y_true.notna()\n",
    "    if not valid_indices.all(): y_true = y_true[valid_indices].astype(int); y_pred = y_pred[valid_indices]\n",
    "    if len(y_true) == 0: print(\" Error: No samples for confusion matrix.\"); return\n",
    "    matrix_labels_expected = mapped_color_ints; conf_matrix = confusion_matrix(y_true, y_pred, labels=matrix_labels_expected); conf_matrix_df = pd.DataFrame(conf_matrix, index=mapped_color_names, columns=mapped_color_names)\n",
    "    plt.figure(figsize=figsize); sns.heatmap(conf_matrix_df, annot=True, fmt='d', cmap=cmap, cbar=True, linewidths=.5, linecolor='lightgray', annot_kws={\"size\": 10})\n",
    "    plt.title('Confusion Matrix: Predicted Color (by Cluster) vs True Color', fontsize=14); plt.ylabel(f'True Color (`{true_color_col}`)', fontsize=12); plt.xlabel(f'Predicted Color (based on `{cluster_col}` Number)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10); plt.yticks(rotation=0, fontsize=10)\n",
    "    plt.tight_layout(); plt.savefig(filepath); print(f\" Saved confusion matrix plot to {filepath}\"); plt.close()\n",
    "    # Removed return statement\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Main Execution Block -> STRUCTURED GRAPH (NO NOISE) + EXPLORE AGENT (V5) + BOC/KMEANS\n",
    "# Includes Cluster Label Remapping for Plotting\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- Parameters ---\n",
    "    NUM_NODES = 180; COLORS = ['blue', 'green', 'red', 'yellow','white', 'Blue']; EDGE_PROBABILITY = 0.20\n",
    "    NUM_SEEDS = 40; NUM_AGENTS = 40; NUM_TRAVERSALS_PER_AGENT = 50; # -> 250 records per seed\n",
    "\n",
    "    # --- Simulation Parameters ---\n",
    "    TARGET_PREFERRED_COUNT = 5 # Agent goal\n",
    "    MAX_STEPS = 50             # Step limit\n",
    "    GRAPH_NOISE_LEVEL = 0.0 # \n",
    "\n",
    "    # --- Clustering Set to BOC + KMEANS ---\n",
    "    N_CLUSTERS = 6\n",
    "    FEATURE_DISTANCE_METHOD = 'boc'\n",
    "    CLUSTER_METHOD = 'kmeans'\n",
    "    DIST_METRIC = 'euclidean' # Metric for Silhouette when using BoC+KMeans features\n",
    "\n",
    "    # --- Output Directory ---\n",
    "    OUTPUT_DIR = f\"clustering_results_{FEATURE_DISTANCE_METHOD}_{CLUSTER_METHOD}_agent_v5_explore_structured_NO_NOISE\" # Updated name\n",
    "    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "    # --- Run Simulation (Agent V5 - Deterministic Preference, NO NOISE Structured Graph) ---\n",
    "    print(f\"--- Starting Simulation Phase (Agent V5 - Deterministic Preference, Structured Graph NO NOISE) ---\")\n",
    "    all_results_list = []; start_time_sim = time.time()\n",
    "    for seed in range(NUM_SEEDS):\n",
    "        graph_attribute_seed = seed; graph_edge_seed = seed + NUM_SEEDS\n",
    "        print(f\"\\nGenerating structured graph for Seed {seed}...\")\n",
    "        G = generate_structured_colored_graph(NUM_NODES, COLORS, EDGE_PROBABILITY,\n",
    "                                              graph_attribute_seed, graph_edge_seed,\n",
    "                                              noise_level=GRAPH_NOISE_LEVEL) # Pass 0.0\n",
    "        # plot_colored_graph(G, seed, output_dir=os.path.join(OUTPUT_DIR, \"graphs\")) # Optional\n",
    "        print(f\"Running Simulation for Seed {seed}...\")\n",
    "        simulation_seed = seed\n",
    "        df_agents = simulate_agents(G, NUM_AGENTS, NUM_TRAVERSALS_PER_AGENT,\n",
    "                                    simulation_seed, EDGE_PROBABILITY,\n",
    "                                    target_preferred_count=TARGET_PREFERRED_COUNT,\n",
    "                                    max_steps=MAX_STEPS,\n",
    "                                    colors_list=COLORS)\n",
    "        all_results_list.append(df_agents)\n",
    "    all_simulation_data = pd.concat(all_results_list, ignore_index=True); end_time_sim = time.time()\n",
    "    print(f\"\\n--- Simulation Phase Complete ---\"); print(f\"Generated {len(all_simulation_data)} records in {end_time_sim - start_time_sim:.2f}s.\")\n",
    "\n",
    "    # --- Run Clustering and Evaluation ---\n",
    "    print(f\"\\n--- Starting Clustering Phase ---\"); start_time_cluster = time.time()\n",
    "    summary_results, data_with_clusters = cluster_and_evaluate(\n",
    "        all_simulation_data.copy(),\n",
    "        n_clusters=N_CLUSTERS,\n",
    "        feature_distance_method=FEATURE_DISTANCE_METHOD, # 'boc'\n",
    "        cluster_method=CLUSTER_METHOD,                 # 'kmeans'\n",
    "        dist_metric_param=DIST_METRIC                  # 'euclidean'\n",
    "    )\n",
    "    end_time_cluster = time.time(); print(f\"\\n--- Clustering Phase Complete ---\"); print(f\"Completed in {end_time_cluster - start_time_cluster:.2f}s.\")\n",
    "\n",
    "    # --- Display and Save Results ---\n",
    "    print(\"\\n--- Clustering Summary Results ---\"); pd.set_option('display.max_rows', 50); pd.set_option('display.max_columns', None); pd.set_option('display.width', 120); pd.set_option('display.max_colwidth', 150)\n",
    "    if not summary_results.empty:\n",
    "        print(summary_results.round(4).to_string()); avg_ari = summary_results['ARI'].mean(); avg_nmi = summary_results['NMI'].mean(); avg_silhouette = summary_results['Silhouette'].mean()\n",
    "        print(\"-\" * 50); print(f\"Avg ARI: {avg_ari:.4f}\"); print(f\"Avg NMI: {avg_nmi:.4f}\"); print(f\"Avg Silhouette: {avg_silhouette:.4f}\"); print(\"-\" * 50)\n",
    "        summary_filename = f\"summary_{FEATURE_DISTANCE_METHOD}_{CLUSTER_METHOD}_k{N_CLUSTERS}_agent_v5_explore_structured_NO_NOISE.csv\"\n",
    "        summary_filepath = os.path.join(OUTPUT_DIR, summary_filename)\n",
    "        try: summary_results.to_csv(summary_filepath, index=False); print(f\"Summary results saved to {summary_filepath}\")\n",
    "        except Exception as e: print(f\"Error saving summary: {e}\")\n",
    "    else: print(\"No summary results generated.\")\n",
    "\n",
    "\n",
    "    # --- Generate and Save Confusion Matrix (with Remapping) ---\n",
    "    if not data_with_clusters.empty and 'Cluster' in data_with_clusters.columns and data_with_clusters['Cluster'].max() > 0 :\n",
    "         print(\"\\n--- Remapping cluster labels for visualization ---\")\n",
    "         # <<< START REMAPPING LOGIC >>>\n",
    "         try:\n",
    "             # Ensure we only use valid clusters for mapping calculation\n",
    "             valid_clusters_df = data_with_clusters[data_with_clusters['Cluster'] > 0].copy()\n",
    "\n",
    "             # Find the majority true label for each original cluster number\n",
    "             # Handle potential multiple modes by taking the first one \n",
    "             mode_map = valid_clusters_df.groupby('Cluster')['Color Preference'].agg(\n",
    "                 lambda x: x.mode()[0] if not x.empty and not x.mode().empty else None\n",
    "             ).to_dict()\n",
    "\n",
    "             # Find the desired integer mapping used by the plotting function (based on sorted unique true labels)\n",
    "             unique_colors = sorted(data_with_clusters['Color Preference'].dropna().unique())\n",
    "             true_color_to_plot_int = {color: i + 1 for i, color in enumerate(unique_colors)}\n",
    "\n",
    "             # Create the final remapping: original_cluster_num -> plot_int_representing_majority_color\n",
    "             remapping_dict = {}\n",
    "             assigned_plot_ints = set() # To check for conflicts\n",
    "             print(f\"  Majority Color per Original Cluster: {mode_map}\")\n",
    "\n",
    "             for original_cluster_num, majority_color_label in mode_map.items():\n",
    "                 if majority_color_label is not None:\n",
    "                     target_int = true_color_to_plot_int.get(majority_color_label)\n",
    "                     if target_int is not None:\n",
    "                         if target_int in assigned_plot_ints:\n",
    "                              warnings.warn(f\"Conflict: Cluster {original_cluster_num} also maps to '{majority_color_label}' (Int {target_int}), which was already assigned. Remapped matrix might not be perfectly diagonal.\", stacklevel=2)\n",
    "                         remapping_dict[original_cluster_num] = target_int\n",
    "                         assigned_plot_ints.add(target_int)\n",
    "                     else:\n",
    "                         print(f\"  Warning: Could not find target integer for majority color '{majority_color_label}' of cluster {original_cluster_num}\")\n",
    "                         remapping_dict[original_cluster_num] = -1 # Assign error label\n",
    "                 else:\n",
    "                      print(f\"  Warning: Cluster {original_cluster_num} was empty or had no mode.\")\n",
    "                      remapping_dict[original_cluster_num] = -1 # Assign error label\n",
    "\n",
    "             print(f\"  Cluster Remapping Dict (Original Cluster -> Target Plot Int): {remapping_dict}\")\n",
    "\n",
    "             # Apply the mapping to create a new column\n",
    "             data_with_clusters['Cluster_Remapped'] = data_with_clusters['Cluster'].map(remapping_dict).fillna(-1).astype(int)\n",
    "\n",
    "             # Plot using the remapped labels\n",
    "             print(\"\\n--- Generating Confusion Matrix (using REMAPPED cluster labels) ---\")\n",
    "             plot_output_dir = os.path.join(OUTPUT_DIR, \"plots_remapped\") # Use a different subdir\n",
    "             # Call plotting function using the NEW column name\n",
    "             plot_color_confusion_matrix(\n",
    "                 data_with_clusters,\n",
    "                 cluster_col='Cluster_Remapped', # <<< USE REMAPPED COLUMN\n",
    "                 true_color_col='Color Preference',\n",
    "                 output_dir=plot_output_dir\n",
    "             )\n",
    "             # Rename the saved plot file to indicate it's remapped\n",
    "             original_plot_name = f\"confusion_matrix_Cluster_Remapped_vs_Color Preference.png\"\n",
    "             new_plot_name = f\"confusion_matrix_REORDERED_{FEATURE_DISTANCE_METHOD}_{CLUSTER_METHOD}_k{N_CLUSTERS}_agent_v5.png\"\n",
    "             try:\n",
    "                 # Create dir if it doesn't exist\n",
    "                 if not os.path.exists(plot_output_dir): os.makedirs(plot_output_dir)\n",
    "                 os.rename(os.path.join(plot_output_dir, original_plot_name), os.path.join(plot_output_dir, new_plot_name))\n",
    "                 print(f\" Renamed plot to {new_plot_name}\")\n",
    "             except Exception as e_mv:\n",
    "                 print(f\" Could not rename remapped plot: {e_mv}\")\n",
    "\n",
    "         except NameError:\n",
    "             # This occurs if the plot function definition is missing\n",
    "             print(\"ERROR: plot_color_confusion_matrix function not defined.\")\n",
    "         except Exception as e:\n",
    "             print(f\"Could not remap labels or generate remapped confusion matrix plot: {e}\")\n",
    "         # <<< END REMAPPING LOGIC >>>\n",
    "\n",
    "    else: print(\"\\nSkipping confusion matrix plot.\")\n",
    "\n",
    "\n",
    "    print(\"\\nPipeline finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce454115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder # If cluster labels are not numeric\n",
    "\n",
    "# 1. Prepare Data\n",
    "valid_data = data_with_clusters[data_with_clusters['Cluster'] > 0].copy()\n",
    "\n",
    "# Target Variable\n",
    "y = valid_data['Cluster']\n",
    "\n",
    "# 2. Prepare Features (Using BoC)\n",
    "corpus = valid_data['Mapped Colors'].apply(lambda colors: ' '.join(map(str, colors if isinstance(colors, list) else [])))\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 3. Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# 4. Choose and Train Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced') \n",
    "print(\"Training classifier...\")\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Classifier Accuracy on Test Set: {classifier.score(X_test, y_test):.4f}\") # Good practice check\n",
    "\n",
    "# 5. Extract and Analyze Feature Importances\n",
    "importances = classifier.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n--- Top Predictors (Features) for Clusters ---\")\n",
    "print(feature_importance_df.head(10)) # Display top 10 overall predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08901b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f85b0e-05af-4d7c-b5e5-3a5dfab9542c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
